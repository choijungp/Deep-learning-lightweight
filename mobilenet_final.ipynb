{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet_final.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHa5Y08JjxQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils import data as D\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import torchsummary\n",
        "import time\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2BfZ1b9kxz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16 \n",
        "validation_ratio = 0.1\n",
        "random_seed = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1fRzvPUkAQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_ratio = 0.1\n",
        "random_seed = 10\n",
        "\n",
        "\n",
        "#데이터셋 설정\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        ### 오버피팅을 방지하기 위해 RandomCrop과 Randam HorizontalFlip같은 노이즈 추가.\n",
        "        transforms.RandomCrop(224, padding=28), #오버피팅 막으려고 랜덤으로 잘라서 이미지 만든다,,,,(?)\n",
        "        transforms.RandomHorizontalFlip(), # 오버피팅 막으려고 이미지 반전시켜서 만든다,,,(?)\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "#validation이나 test는 그런 것 필요 없음\n",
        "transform_validation = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "\n",
        "#데이터 세트 다운로드\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "validset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_validation)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "#                                          shuffle=True, num_workers=0)\n",
        "\n",
        "num_train = len(trainset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(validation_ratio * num_train))\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "\n",
        "# train_loader에 데이터를 로드 해오는 코드들\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
        ")\n",
        "\n",
        "#10개 클래스로 구분\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# 초기 학습률\n",
        "initial_lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CubT6EwlkdzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class depthwise_conv(nn.Module):\n",
        "    # __init__()에서 모델의 구조와 동작을 정의하는 생성자를 정의(속성값을 초기화하는 역할로, 객체가 생성될 때 자동으호 호출)\n",
        "    def __init__(self, nin, kernel_size, padding, bias=False, stride=1):\n",
        "        super(depthwise_conv, self).__init__() # super() 함수를 부르면 여기서 만든 클래스는 nn.Module 클래스의 속성들을 가지고 초기화\n",
        "        #nn.conv2D 모듈 : 첫번째는 입력 채널 수, 두번째변수는 출력 채널 수 세번째는 커널 사이즈(숫자하나만 지정하면 정사각형으로 간주)\n",
        "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, stride=stride, padding=padding, groups=nin, bias=bias)\n",
        "        #self.depthwise는 이제 nin 크기의 받아서 nin 크기의 출력을 하는 conv2D 함수가 됨.\n",
        "\n",
        "    #foward() 함수는 모델이 학습데이터를 입력받아서 forward 연산을 진행시키는 함수\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)  #self.depthwise 실행하고 반환\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WKIOixwke-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dw_block(nn.Module):\n",
        "    def __init__(self, nin, kernel_size, padding=1, bias=False, stride=1):\n",
        "        super(dw_block, self).__init__()\n",
        "        self.dw_block = nn.Sequential(\n",
        "            depthwise_conv(nin, kernel_size, padding, bias, stride),\n",
        "            #BatchNorm2d(배치 정규화): 학습률을 너무 높게 잡으면 기울기가 소실되거나 발산하는 증상을 예방하여 학습과정을 안정화하는 방법\n",
        "            nn.BatchNorm2d(nin),\n",
        "            ##distribution을 평균 0, 표준편차 1인 input으로 normalize시키는 방법\n",
        "            ##Training 할 때는 batch의 평균과 분산으로 normalize 하고, Test 할 때는 계산해놓은 이동 평균(training 때 계산)으로 normalize\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.dw_block(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqkWiC2-lDdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class one_by_one_block(nn.Module):\n",
        "    def __init__(self, nin, nout, padding=0, bias=False, stride=1):\n",
        "        super(one_by_one_block, self).__init__()\n",
        "        self.one_by_one_block = nn.Sequential(\n",
        "            #커널 사이즈 1x1 로 컨벌루션 진행\n",
        "            nn.Conv2d(nin, nout, kernel_size=1, stride=stride, padding=padding, bias=bias),\n",
        "            nn.BatchNorm2d(nout),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.one_by_one_block(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abn-Xojngms5",
        "colab": {}
      },
      "source": [
        "#########################################################################\n",
        "#           Mobilenet+Bottleneck+Shortcut v3                            #\n",
        "#           block에 들어갈때 1/2, 나갈때 2배(다시 복구)                 #\n",
        "#           5번 반복 부분에서 block 들어갈때 1/4, 나갈때 4배(다시 복구) #\n",
        "#           마지막(1024연산) 부분에서도 bottleneck 적용                 #\n",
        "#           불필요한 1x1 삭제                                           #\n",
        "#########################################################################\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "  \n",
        "    def __init__(self, input_channel, num_classes=10):\n",
        "        super(MobileNet, self).__init__()\n",
        "        \n",
        "        self.block1 = nn.Sequential(\n",
        "            #nn.conv2D 모듈 : 첫번째는 입력 채널 수, 두번째변수는 출력 채널 수 세번째는 커널 사이즈(숫자하나만 지정하면 정사각형으로 간주)\n",
        "            #BatchNorm2d(배치 정규화): 학습률을 너무 높게 잡으면 기울기가 소실되거나 발산하는 증상을 예방하여 학습과정을 안정화하는 방법\n",
        "            #계층에 들어가는 입력을 평균과 분산으로 정규화함.\n",
        "            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        #112x112x32\n",
        "        ###identity 저장\n",
        "        self.block2=nn.Sequential(\n",
        "            dw_block(32, kernel_size=3), #depthwise convolution / stride=1\n",
        "        )\n",
        "        ###resnet 작용하기 위해 downsampling넣기\n",
        "        self.block3=nn.Sequential( \n",
        "            nn.ReLU(),  \n",
        "            one_by_one_block(32, 64), #one_by_one convolution\n",
        "            #112x112x64\n",
        "            dw_block(64, kernel_size=3, stride=2), \n",
        "        )\n",
        "        #56x56x64\n",
        "        ###identity 저장\n",
        "        self.block4=nn.Sequential(\n",
        "            one_by_one_block(64, 64),\n",
        "            dw_block(64, kernel_size=3),\n",
        "        )\n",
        "        ###resnet 작용하기 위해 downsampling넣기\n",
        "        self.block5=nn.Sequential(    \n",
        "            one_by_one_block(64, 128),\n",
        "            #56x56x128\n",
        "            nn.ReLU(),\n",
        "            dw_block(128, kernel_size=3, stride=2),\n",
        "        )\n",
        "        #28x28x128\n",
        "        ###identity 저장\n",
        "        self.block6=nn.Sequential( \n",
        "            one_by_one_block(128, 128),\n",
        "            dw_block(128, kernel_size=3),\n",
        "        )\n",
        "        #resnet 작용하기 위해 downsampling넣기\n",
        "        self.block7=nn.Sequential(\n",
        "            one_by_one_block(128, 256),\n",
        "            #28x28x256\n",
        "            nn.ReLU(),\n",
        "            dw_block(256, kernel_size=3, stride=2),\n",
        "        )\n",
        "        #14x14x256\n",
        "        #identity 저장\n",
        "        self.block8=nn.Sequential(\n",
        "            one_by_one_block(256, 128),\n",
        "            #14x14x128   \n",
        "            # 5 times \n",
        "            dw_block(128, kernel_size=3),\n",
        "            one_by_one_block(128, 128),\n",
        "            dw_block(128, kernel_size=3),\n",
        "            one_by_one_block(128, 128),\n",
        "            dw_block(128, kernel_size=3),\n",
        "            one_by_one_block(128, 128),\n",
        "            dw_block(128, kernel_size=3),\n",
        "            one_by_one_block(128, 128),\n",
        "            dw_block(128, kernel_size=3),\n",
        "            one_by_one_block(128, 256),\n",
        "        )\n",
        "        #14x14x256\n",
        "        #resnet 작용하기 위해 downsampling넣기\n",
        "        self.block9=nn.Sequential(\n",
        "            one_by_one_block(256, 512),\n",
        "            nn.ReLU(),\n",
        "            dw_block(512, kernel_size=3, stride=2),\n",
        "        )\n",
        "        #7x7x512\n",
        "        #identity 저장\n",
        "        self.block10=nn.Sequential(\n",
        "            one_by_one_block(512, 512),\n",
        "            #7x7x512\n",
        "            dw_block(512, kernel_size=3, padding=4, stride=2),\n",
        "        )\n",
        "        #7x7x512\n",
        "        #resnet 작용하기 위해 downsampling넣기\n",
        "        self.block11=nn.Sequential(\n",
        "            one_by_one_block(512, 1024),\n",
        "        )\n",
        "        #7x7x1024\n",
        "        #avgPool->1x1x1024  \n",
        "\n",
        "        #Fully Connected layer      \n",
        "        self.fc_v2 = nn.Conv2d(1024, num_classes, 1, 1, groups=2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        identity = x\n",
        "        x = self.block2(x)\n",
        "        #112x112x32\n",
        "        x += identity\n",
        "\n",
        "        x = self.block3(x)\n",
        "        identity = x\n",
        "        x = self.block4(x)\n",
        "        x += identity\n",
        "\n",
        "        x = self.block5(x)\n",
        "        identity = x\n",
        "        x = self.block6(x)\n",
        "        x += identity\n",
        "\n",
        "        x = self.block7(x)\n",
        "        identity = x\n",
        "        x = self.block8(x)\n",
        "        x += identity\n",
        "\n",
        "        x = self.block9(x)\n",
        "        identity = x\n",
        "        x = self.block10(x)\n",
        "        x += identity\n",
        "        x = self.block11(x)\n",
        "        \n",
        "        body_output = x\n",
        "        \n",
        "        avg_pool_output = F.adaptive_avg_pool2d(body_output, (1, 1))\n",
        "        output = self.fc_v2(avg_pool_output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_i64UbYigms-",
        "colab": {}
      },
      "source": [
        "net = MobileNet(3, 10) #아마도 인풋채널3개(RGB), 클래스 10개 로 추정됨!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HRfmSKi5gmtC",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #GPU있고 cuda를 쓸수 있으면 쿠다를 쓰게 하고 없으면 cpu 쓰게함\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Zr57LaIgmtF",
        "colab": {}
      },
      "source": [
        "net.to(device) #이용가능한 device(cpu or Gpu)에 네트워크 전송"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y1t-m9rYbD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torchsummary.summary(net, (3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uf9wsm7ZgmtK",
        "colab": {}
      },
      "source": [
        "start = time.time()  # 시작 시간 저장\n",
        "criterion = nn.CrossEntropyLoss() #(binary 아닌)여러 클래스의 loss구하는 함수\n",
        "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9) ##optimizer(SGD방식): 역전파과정에서 loss function의 값을 줄여나가며 학습시킴(가중치 업데이트)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "for epoch in range(1):  \n",
        "    if epoch == 0:\n",
        "        lr = initial_lr\n",
        "    elif epoch % 2 == 0 and epoch != 0:\n",
        "        lr *= 0.94\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data  #데이터의 인풋 받아온다.s\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels) #결과와 라벨을 비교해서 loss를 구한다.\n",
        "        loss.backward() #loss를 backward해서 기울기(미분치)를 구한다. -> 맞나?\n",
        "        optimizer.step() #한 스텝 이동\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        show_period = 250\n",
        "        if i % show_period == show_period-1:    # print every \"show_period\" mini-batches\n",
        "            print('[%d, %5d] loss: %.7f' %\n",
        "                  (epoch + 1, i + 1, running_loss / show_period))\n",
        "            running_loss = 0.0\n",
        "       \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, data in enumerate(valid_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct = correct + (predicted == labels).sum().item() #맞으면 correct하고 추가함\n",
        "        \n",
        "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
        "          (epoch, 100 * correct / total)\n",
        "         )\n",
        "\n",
        "print('Finished Training')\n",
        "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgtaOpd1fNWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = net.state_dict()\n",
        "torch.save(params, \"net.prm\", pickle_protocol = 4)\n",
        "params = torch.load(\"net.prm\", map_location = \"cpu\")\n",
        "net.load_state_dict(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ZHHvkIH2q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################### Miok ###############################\n",
        "#net.cpu()\n",
        "x = torch.randn(batch_size, 3, 224, 224, requires_grad=True, device='cuda')\n",
        "torch_out = net.cuda() #모델을 cuda로 학습시켰으니 cuda로 맞춰주기\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(net,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"mobilenet.onnx\",   # where to save the model (can be a file or file-like object), 네트워크 구조와 내 보낸 모델의 매개 변수 (이 경우 peleent)를 모두 포함하는 이진 프로토 타입 파일입니다.\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sx_PPtQH4_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install onnx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TcbxBQ4IKNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import onnx\n",
        "\n",
        "# Load the onnx model\n",
        "model = onnx.load('mobilenet.onnx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Me7km8ZILqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = onnx.load('mobilenet.onnx')\n",
        "\n",
        "# 위와 같이 읽어서 알아볼 수 있는 형태의 그래프 포멧으로 출력 \n",
        "onnx.helper.printable_graph(model.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhrsBt0QT1QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install onnxruntime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PaG0hNJIVJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#onnxruntime을 ort로 가져 오기\n",
        "import onnxruntime as ort\n",
        "\n",
        "ort_session = ort.InferenceSession('mobilenet.onnx')\n",
        "outputs = ort_session.run(None, {'input': np.random.randn(batch_size, 3, 224, 224).astype(np.float32)})\n",
        "\n",
        "print(outputs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvb5SrOIVwMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install onnx-tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KLxJuGzY12Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69TQaBzbYp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/onnx/onnx-tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AULaQv6sbrx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " cd onnx-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUXZv7gVbdfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USExlYIzclyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4lZi527VWjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onnx-tf convert -i mobilenet.onnx -o saved_model.pb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCjbYdkjr8sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q-zoZxtoUFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# make a converter object from the saved tensorflow file\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/', tags=['train']]\n",
        "\n",
        "# tell converter which type of optimization techniques to use\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# to view the best option for optimization read documentation of tflite about optimization go to this link https://www.tensorflow.org/lite/guide/get_started#4_optimize_your_model_optional\n",
        "\n",
        "# convert the model \n",
        "tf_lite_model = converter.convert()\n",
        "# save the converted model \n",
        "open('eye_state_model_tensorFlowopt.tflite', 'wb').write(tf_lite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}