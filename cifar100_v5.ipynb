{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar100_v5.ipynb","provenance":[],"authorship_tag":"ABX9TyONsVA2mFlacQ3vrUNLBjGJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b29ea550345d401aad4490d27aaf596f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_abe82b67fabd4e16b715e1671efc4732","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_062dc9c9e4394fd2acd2ae1fdb3466e2","IPY_MODEL_2c3bc64d748c47b5a12b6cc2a3227ce6"]}},"abe82b67fabd4e16b715e1671efc4732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"062dc9c9e4394fd2acd2ae1fdb3466e2":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c7f38c55de244be08010dd95af07da77","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81d86211e77a4c899924b12fd357539d"}},"2c3bc64d748c47b5a12b6cc2a3227ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0dc5284b50844eaebd9d4d70cd0be42c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169009152/? [00:20&lt;00:00, 33989364.10it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67674b7c5b6048859eb5f08977e6826d"}},"c7f38c55de244be08010dd95af07da77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81d86211e77a4c899924b12fd357539d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0dc5284b50844eaebd9d4d70cd0be42c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"67674b7c5b6048859eb5f08977e6826d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"R4g9r8hzEPjq","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import os\n","import glob\n","import PIL\n","from PIL import Image\n","from torch.utils import data as D\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.optim.lr_scheduler import _LRScheduler\n","import random\n","import torchsummary\n","from torch.utils.data import DataLoader\n","import time\n","from datetime import datetime\n","from torch.autograd import Variable\n","\n","CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n","CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n","MILESTONES = [20, 40, 80] #learning rate 값을 60 epoch, 120 epoch, 160 epoch 별로 어떻게 하겠따.\n","CHECKPOINT_PATH = 'checkpoint'\n","TIME_NOW = datetime.now().isoformat()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vp_byAUAESWA","colab_type":"code","colab":{}},"source":["num_workers = 4\n","batch_size = 64 \n","validation_ratio = 0.1\n","random_seed = 10 \n","EPOCH = 100\n","lr = 0.1\n","warm = 1\n","SAVE_EPOCH=10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1er6Qg5PeaM","colab_type":"code","colab":{}},"source":["class depthwise_conv(nn.Module):\n","    # __init__()에서 모델의 구조와 동작을 정의하는 생성자를 정의(속성값을 초기화하는 역할로, 객체가 생성될 때 자동으호 호출)\n","    def __init__(self, nin, kernel_size, padding, bias=False, stride=1):\n","        super(depthwise_conv, self).__init__() # super() 함수를 부르면 여기서 만든 클래스는 nn.Module 클래스의 속성들을 가지고 초기화\n","        #nn.conv2D 모듈 : 첫번째는 입력 채널 수, 두번째변수는 출력 채널 수 세번째는 커널 사이즈(숫자하나만 지정하면 정사각형으로 간주)\n","        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernel_size, stride=stride, padding=padding, groups=nin, bias=bias)\n","        #self.depthwise는 이제 nin 크기의 받아서 nin 크기의 출력을 하는 conv2D 함수가 됨.\n","\n","    #foward() 함수는 모델이 학습데이터를 입력받아서 forward 연산을 진행시키는 함수\n","    def forward(self, x):\n","        out = self.depthwise(x)  #self.depthwise 실행하고 반환\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BHyJqbKPfYA","colab_type":"code","colab":{}},"source":["class dw_block(nn.Module):\n","    def __init__(self, nin, kernel_size, padding=1, bias=False, stride=1):\n","        super(dw_block, self).__init__()\n","        self.dw_block = nn.Sequential(\n","            depthwise_conv(nin, kernel_size, padding, bias, stride),\n","            #BatchNorm2d(배치 정규화): 학습률을 너무 높게 잡으면 기울기가 소실되거나 발산하는 증상을 예방하여 학습과정을 안정화하는 방법\n","            nn.BatchNorm2d(nin),\n","            ##distribution을 평균 0, 표준편차 1인 input으로 normalize시키는 방법\n","            ##Training 할 때는 batch의 평균과 분산으로 normalize 하고, Test 할 때는 계산해놓은 이동 평균(training 때 계산)으로 normalize\n","            nn.ReLU()\n","        )\n","    def forward(self, x):\n","        out = self.dw_block(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lmf7tjX_PhSK","colab_type":"code","colab":{}},"source":["class one_by_one_block(nn.Module):\n","    def __init__(self, nin, nout, padding=0, bias=False, stride=1):\n","        super(one_by_one_block, self).__init__()\n","        self.one_by_one_block = nn.Sequential(\n","            #커널 사이즈 1x1 로 컨벌루션 진행\n","            nn.Conv2d(nin, nout, kernel_size=1, stride=stride, padding=padding, bias=bias),\n","            nn.BatchNorm2d(nout),\n","            nn.ReLU()\n","        )\n","    def forward(self, x):\n","        out = self.one_by_one_block(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAdZIRjrPiUU","colab_type":"code","colab":{}},"source":["#########################################\n","#           Original Mobilenet          #\n","#########################################\n","\n","class MobileNet(nn.Module):\n","  \n","    def __init__(self, input_channel, num_classes=10):\n","        super(MobileNet, self).__init__()\n","        \n","        self.network = nn.Sequential(\n","            #nn.conv2D 모듈 : 첫번째는 입력 채널 수, 두번째변수는 출력 채널 수 세번째는 커널 사이즈(숫자하나만 지정하면 정사각형으로 간주)\n","            #BatchNorm2d(배치 정규화): 학습률을 너무 높게 잡으면 기울기가 소실되거나 발산하는 증상을 예방하여 학습과정을 안정화하는 방법\n","            #계층에 들어가는 입력을 평균과 분산으로 정규화함.\n","            nn.Conv2d(input_channel, 32, kernel_size=3, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True),\n","            \n","            dw_block(32, kernel_size=3), #depthwise convolution\n","            one_by_one_block(32, 64), #one_by_one convolution\n","            \n","            dw_block(64, kernel_size=3, stride=2),\n","            one_by_one_block(64, 128),\n","            \n","            dw_block(128, kernel_size=3),\n","            one_by_one_block(128, 128),\n","            \n","            dw_block(128, kernel_size=3, stride=2),\n","            one_by_one_block(128, 256),\n","            \n","            dw_block(256, kernel_size=3),\n","            one_by_one_block(256, 256),\n","            \n","            dw_block(256, kernel_size=3, stride=2),\n","            one_by_one_block(256, 512),\n","            \n","            # 5 times \n","            dw_block(512, kernel_size=3),\n","            one_by_one_block(512, 512),\n","            dw_block(512, kernel_size=3),\n","            one_by_one_block(512, 512),\n","            dw_block(512, kernel_size=3),\n","            one_by_one_block(512, 512),\n","            dw_block(512, kernel_size=3),\n","            one_by_one_block(512, 512),\n","            dw_block(512, kernel_size=3),\n","            one_by_one_block(512, 512),\n","            \n","            dw_block(512, kernel_size=3, padding=4,stride=2),\n","            one_by_one_block(512, 1024),\n","            \n","            dw_block(1024, kernel_size=3, padding=4, stride=2),\n","            one_by_one_block(1024, 1024),\n","        )\n","                \n","        self.linear = nn.Linear(1024, num_classes)\n","        \n","    def forward(self, x):\n","        body_output = self.network(x)\n","        \n","        avg_pool_output = F.adaptive_avg_pool2d(body_output, (1, 1))\n","        avg_pool_flat = avg_pool_output.view(avg_pool_output.size(0), -1)\n","\n","        output = self.linear(avg_pool_flat)\n","        \n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Q91OwROPsLR","colab_type":"code","colab":{}},"source":["net = MobileNet(3, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqCavGsCPuGJ","colab_type":"code","colab":{}},"source":["def get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n","    \"\"\" return training dataloader\n","    Args:\n","        mean: mean of cifar100 training dataset\n","        std: std of cifar100 training dataset\n","        path: path to cifar100 training python dataset\n","        batch_size: dataloader batchsize\n","        num_workers: dataloader num_works\n","        shuffle: whether to shuffle \n","    Returns: train_data_loader:torch dataloader object\n","    \"\"\"\n","\n","    transform_train = transforms.Compose([\n","        #transforms.ToPILImage(),\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(15),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","    #cifar100_training = CIFAR100Train(path, transform=transform_train)\n","    cifar100_training = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n","    cifar100_training_loader = DataLoader(\n","        cifar100_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n","\n","    return cifar100_training_loader\n","\n","def get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n","    \"\"\" return training dataloader\n","    Args:\n","        mean: mean of cifar100 test dataset\n","        std: std of cifar100 test dataset\n","        path: path to cifar100 test python dataset\n","        batch_size: dataloader batchsize\n","        num_workers: dataloader num_works\n","        shuffle: whether to shuffle \n","    Returns: cifar100_test_loader:torch dataloader object\n","    \"\"\"\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","    #cifar100_test = CIFAR100Test(path, transform=transform_test)\n","    cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n","    cifar100_test_loader = DataLoader(\n","        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n","    \n","    return cifar100_test_loader\n","\n","class WarmUpLR(_LRScheduler):\n","    \"\"\"warmup_training learning rate scheduler\n","    Args:\n","        optimizer: optimzier(e.g. SGD)\n","        total_iters: totoal_iters of warmup phase\n","    \"\"\"\n","    def __init__(self, optimizer, total_iters, last_epoch=-1):\n","        \n","        self.total_iters = total_iters\n","        super().__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        \"\"\"we will use the first m batches, and set the learning\n","        rate to base_lr * m / total_iters\n","        \"\"\"\n","        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3w5bh3zPvfl","colab_type":"code","outputId":"0934ce2f-8be2-47bd-99e7-eb871da085bb","executionInfo":{"status":"ok","timestamp":1586299536452,"user_tz":-540,"elapsed":13230,"user":{"displayName":"최정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOwCv_0jzikdoT0QBkbWD7Jer4x6EFE8yhgKIWcw=s64","userId":"17948791789031637578"}},"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["b29ea550345d401aad4490d27aaf596f","abe82b67fabd4e16b715e1671efc4732","062dc9c9e4394fd2acd2ae1fdb3466e2","2c3bc64d748c47b5a12b6cc2a3227ce6","c7f38c55de244be08010dd95af07da77","81d86211e77a4c899924b12fd357539d","0dc5284b50844eaebd9d4d70cd0be42c","67674b7c5b6048859eb5f08977e6826d"]}},"source":["###================================ Dataset Resize ================================###\n","#데이터셋 설정\n","transform_train = transforms.Compose([\n","        transforms.Resize(224),\n","        ### 오버피팅을 방지하기 위해 RandomCrop과 Randam HorizontalFlip같은 노이즈 추가.\n","        transforms.RandomCrop(224, padding=28), #오버피팅 막으려고 랜덤으로 잘라서 이미지 만든다,,,,(?)\n","        transforms.RandomHorizontalFlip(), # 오버피팅 막으려고 이미지 반전시켜서 만든다,,,(?)\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n","\n","#validation이나 test는 그런 것 필요 없음\n","transform_validation = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n","\n","\n","transform_test = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n","###================================ Dataset Resize ================================###\n","\n","cifar100_training_loader = get_training_dataloader(\n","        CIFAR100_TRAIN_MEAN,\n","        CIFAR100_TRAIN_STD,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        shuffle=True\n","    )\n","\n","cifar100_test_loader = get_test_dataloader(\n","        CIFAR100_TRAIN_MEAN,\n","        CIFAR100_TRAIN_STD,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        shuffle=False\n","    )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b29ea550345d401aad4490d27aaf596f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O0Hpgy2uPwwt","colab_type":"code","outputId":"33c9513f-24d9-42bd-859f-437843444e9b","executionInfo":{"status":"ok","timestamp":1586299536456,"user_tz":-540,"elapsed":13194,"user":{"displayName":"최정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOwCv_0jzikdoT0QBkbWD7Jer4x6EFE8yhgKIWcw=s64","userId":"17948791789031637578"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #GPU있고 cuda를 쓸수 있으면 쿠다를 쓰게 하고 없으면 cpu 쓰게함\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"elCOWboKPzvF","colab_type":"code","outputId":"1259b978-eed8-42ea-98fe-41368a21808c","executionInfo":{"status":"ok","timestamp":1586299546519,"user_tz":-540,"elapsed":23218,"user":{"displayName":"최정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOwCv_0jzikdoT0QBkbWD7Jer4x6EFE8yhgKIWcw=s64","userId":"17948791789031637578"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["net.to(device) #이용가능한 device(cpu or Gpu)에 네트워크 전송"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MobileNet(\n","  (network): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        )\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (4): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (5): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","        )\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (6): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (7): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n","        )\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (8): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (9): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n","        )\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (10): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (11): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (12): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (13): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","        )\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (14): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (15): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (16): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (17): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (18): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (19): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (20): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (21): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (22): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (23): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (24): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (25): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4), groups=512, bias=False)\n","        )\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (26): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (27): dw_block(\n","      (dw_block): Sequential(\n","        (0): depthwise_conv(\n","          (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4), groups=1024, bias=False)\n","        )\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","    (28): one_by_one_block(\n","      (one_by_one_block): Sequential(\n","        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=1024, out_features=100, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"k8feVJvGKXaL","colab_type":"code","outputId":"e7f71dd3-c794-48f3-8c38-c3fb4c8f0c9e","executionInfo":{"status":"ok","timestamp":1586299546524,"user_tz":-540,"elapsed":23189,"user":{"displayName":"최정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOwCv_0jzikdoT0QBkbWD7Jer4x6EFE8yhgKIWcw=s64","userId":"17948791789031637578"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["torchsummary.summary(net, (3, 224, 224))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 112, 112]             864\n","       BatchNorm2d-2         [-1, 32, 112, 112]              64\n","              ReLU-3         [-1, 32, 112, 112]               0\n","            Conv2d-4         [-1, 32, 112, 112]             288\n","    depthwise_conv-5         [-1, 32, 112, 112]               0\n","       BatchNorm2d-6         [-1, 32, 112, 112]              64\n","              ReLU-7         [-1, 32, 112, 112]               0\n","          dw_block-8         [-1, 32, 112, 112]               0\n","            Conv2d-9         [-1, 64, 112, 112]           2,048\n","      BatchNorm2d-10         [-1, 64, 112, 112]             128\n","             ReLU-11         [-1, 64, 112, 112]               0\n"," one_by_one_block-12         [-1, 64, 112, 112]               0\n","           Conv2d-13           [-1, 64, 56, 56]             576\n","   depthwise_conv-14           [-1, 64, 56, 56]               0\n","      BatchNorm2d-15           [-1, 64, 56, 56]             128\n","             ReLU-16           [-1, 64, 56, 56]               0\n","         dw_block-17           [-1, 64, 56, 56]               0\n","           Conv2d-18          [-1, 128, 56, 56]           8,192\n","      BatchNorm2d-19          [-1, 128, 56, 56]             256\n","             ReLU-20          [-1, 128, 56, 56]               0\n"," one_by_one_block-21          [-1, 128, 56, 56]               0\n","           Conv2d-22          [-1, 128, 56, 56]           1,152\n","   depthwise_conv-23          [-1, 128, 56, 56]               0\n","      BatchNorm2d-24          [-1, 128, 56, 56]             256\n","             ReLU-25          [-1, 128, 56, 56]               0\n","         dw_block-26          [-1, 128, 56, 56]               0\n","           Conv2d-27          [-1, 128, 56, 56]          16,384\n","      BatchNorm2d-28          [-1, 128, 56, 56]             256\n","             ReLU-29          [-1, 128, 56, 56]               0\n"," one_by_one_block-30          [-1, 128, 56, 56]               0\n","           Conv2d-31          [-1, 128, 28, 28]           1,152\n","   depthwise_conv-32          [-1, 128, 28, 28]               0\n","      BatchNorm2d-33          [-1, 128, 28, 28]             256\n","             ReLU-34          [-1, 128, 28, 28]               0\n","         dw_block-35          [-1, 128, 28, 28]               0\n","           Conv2d-36          [-1, 256, 28, 28]          32,768\n","      BatchNorm2d-37          [-1, 256, 28, 28]             512\n","             ReLU-38          [-1, 256, 28, 28]               0\n"," one_by_one_block-39          [-1, 256, 28, 28]               0\n","           Conv2d-40          [-1, 256, 28, 28]           2,304\n","   depthwise_conv-41          [-1, 256, 28, 28]               0\n","      BatchNorm2d-42          [-1, 256, 28, 28]             512\n","             ReLU-43          [-1, 256, 28, 28]               0\n","         dw_block-44          [-1, 256, 28, 28]               0\n","           Conv2d-45          [-1, 256, 28, 28]          65,536\n","      BatchNorm2d-46          [-1, 256, 28, 28]             512\n","             ReLU-47          [-1, 256, 28, 28]               0\n"," one_by_one_block-48          [-1, 256, 28, 28]               0\n","           Conv2d-49          [-1, 256, 14, 14]           2,304\n","   depthwise_conv-50          [-1, 256, 14, 14]               0\n","      BatchNorm2d-51          [-1, 256, 14, 14]             512\n","             ReLU-52          [-1, 256, 14, 14]               0\n","         dw_block-53          [-1, 256, 14, 14]               0\n","           Conv2d-54          [-1, 512, 14, 14]         131,072\n","      BatchNorm2d-55          [-1, 512, 14, 14]           1,024\n","             ReLU-56          [-1, 512, 14, 14]               0\n"," one_by_one_block-57          [-1, 512, 14, 14]               0\n","           Conv2d-58          [-1, 512, 14, 14]           4,608\n","   depthwise_conv-59          [-1, 512, 14, 14]               0\n","      BatchNorm2d-60          [-1, 512, 14, 14]           1,024\n","             ReLU-61          [-1, 512, 14, 14]               0\n","         dw_block-62          [-1, 512, 14, 14]               0\n","           Conv2d-63          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n","             ReLU-65          [-1, 512, 14, 14]               0\n"," one_by_one_block-66          [-1, 512, 14, 14]               0\n","           Conv2d-67          [-1, 512, 14, 14]           4,608\n","   depthwise_conv-68          [-1, 512, 14, 14]               0\n","      BatchNorm2d-69          [-1, 512, 14, 14]           1,024\n","             ReLU-70          [-1, 512, 14, 14]               0\n","         dw_block-71          [-1, 512, 14, 14]               0\n","           Conv2d-72          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-73          [-1, 512, 14, 14]           1,024\n","             ReLU-74          [-1, 512, 14, 14]               0\n"," one_by_one_block-75          [-1, 512, 14, 14]               0\n","           Conv2d-76          [-1, 512, 14, 14]           4,608\n","   depthwise_conv-77          [-1, 512, 14, 14]               0\n","      BatchNorm2d-78          [-1, 512, 14, 14]           1,024\n","             ReLU-79          [-1, 512, 14, 14]               0\n","         dw_block-80          [-1, 512, 14, 14]               0\n","           Conv2d-81          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-82          [-1, 512, 14, 14]           1,024\n","             ReLU-83          [-1, 512, 14, 14]               0\n"," one_by_one_block-84          [-1, 512, 14, 14]               0\n","           Conv2d-85          [-1, 512, 14, 14]           4,608\n","   depthwise_conv-86          [-1, 512, 14, 14]               0\n","      BatchNorm2d-87          [-1, 512, 14, 14]           1,024\n","             ReLU-88          [-1, 512, 14, 14]               0\n","         dw_block-89          [-1, 512, 14, 14]               0\n","           Conv2d-90          [-1, 512, 14, 14]         262,144\n","      BatchNorm2d-91          [-1, 512, 14, 14]           1,024\n","             ReLU-92          [-1, 512, 14, 14]               0\n"," one_by_one_block-93          [-1, 512, 14, 14]               0\n","           Conv2d-94          [-1, 512, 14, 14]           4,608\n","   depthwise_conv-95          [-1, 512, 14, 14]               0\n","      BatchNorm2d-96          [-1, 512, 14, 14]           1,024\n","             ReLU-97          [-1, 512, 14, 14]               0\n","         dw_block-98          [-1, 512, 14, 14]               0\n","           Conv2d-99          [-1, 512, 14, 14]         262,144\n","     BatchNorm2d-100          [-1, 512, 14, 14]           1,024\n","            ReLU-101          [-1, 512, 14, 14]               0\n","one_by_one_block-102          [-1, 512, 14, 14]               0\n","          Conv2d-103          [-1, 512, 10, 10]           4,608\n","  depthwise_conv-104          [-1, 512, 10, 10]               0\n","     BatchNorm2d-105          [-1, 512, 10, 10]           1,024\n","            ReLU-106          [-1, 512, 10, 10]               0\n","        dw_block-107          [-1, 512, 10, 10]               0\n","          Conv2d-108         [-1, 1024, 10, 10]         524,288\n","     BatchNorm2d-109         [-1, 1024, 10, 10]           2,048\n","            ReLU-110         [-1, 1024, 10, 10]               0\n","one_by_one_block-111         [-1, 1024, 10, 10]               0\n","          Conv2d-112           [-1, 1024, 8, 8]           9,216\n","  depthwise_conv-113           [-1, 1024, 8, 8]               0\n","     BatchNorm2d-114           [-1, 1024, 8, 8]           2,048\n","            ReLU-115           [-1, 1024, 8, 8]               0\n","        dw_block-116           [-1, 1024, 8, 8]               0\n","          Conv2d-117           [-1, 1024, 8, 8]       1,048,576\n","     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n","            ReLU-119           [-1, 1024, 8, 8]               0\n","one_by_one_block-120           [-1, 1024, 8, 8]               0\n","          Linear-121                  [-1, 100]         102,500\n","================================================================\n","Total params: 3,309,476\n","Trainable params: 3,309,476\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 169.21\n","Params size (MB): 12.62\n","Estimated Total Size (MB): 182.41\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J-4kw_GNP1rX","colab_type":"code","colab":{}},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n","train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=0.2) #learning rate decay\n","#20, 40, 80\n","# 20 <= epoch < 40, lr = lr*0.2 \n","iter_per_epoch = len(cifar100_training_loader)\n","warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * warm)\n","checkpoint_path = os.path.join(CHECKPOINT_PATH, \"MobileNet\", TIME_NOW)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdP_Qq_MP2mw","colab_type":"code","colab":{}},"source":["def train(epoch):\n","\n","    net.train()\n","    num_trained_data = 0\n","    for batch_index, (images, labels) in enumerate(cifar100_training_loader):\n","        if epoch <= warm:\n","            warmup_scheduler.step()\n","\n","        images = Variable(images)\n","        labels = Variable(labels)\n","\n","        labels = labels.cuda()\n","        images = images.cuda()\n","        \n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        n_iter = (epoch - 1) * len(cifar100_training_loader) + batch_index + 1\n","        num_trained_data += len(images)\n","        '''print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n","            loss.item(),\n","            optimizer.param_groups[0]['lr'],\n","            epoch=epoch,\n","            trained_samples= num_trained_data,\n","            total_samples=len(cifar100_training_loader.dataset)\n","        ))'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9No0KOyiP4Xv","colab_type":"code","colab":{}},"source":["def eval_training(epoch):\n","    net.eval()\n","\n","    test_loss = 0.0 # cost function error\n","    correct = 0.0\n","\n","    for (images, labels) in cifar100_test_loader:\n","        images = Variable(images)\n","        labels = Variable(labels)\n","\n","        images = images.cuda()\n","        labels = labels.cuda()\n","\n","        outputs = net(images)\n","        loss = loss_function(outputs, labels)\n","        test_loss += loss.item()\n","        _, preds = outputs.max(1)\n","        correct += preds.eq(labels).sum()\n","\n","    print('[', epoch, 'epoch]')\n","    print('Test set: Average loss: {:.4f}, Accuracy: {:.4f}'.format(\n","        test_loss / len(cifar100_test_loader.dataset),\n","        correct.float() / len(cifar100_test_loader.dataset)\n","    ))\n","    print()\n","\n","    return correct.float() / len(cifar100_test_loader.dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zo8isKesP5rt","colab_type":"code","outputId":"06888856-88a9-46bc-f3df-c492ad928e49","executionInfo":{"status":"ok","timestamp":1586302118504,"user_tz":-540,"elapsed":2473738,"user":{"displayName":"최정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOwCv_0jzikdoT0QBkbWD7Jer4x6EFE8yhgKIWcw=s64","userId":"17948791789031637578"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[" if not os.path.exists(checkpoint_path):\n","        os.makedirs(checkpoint_path)\n","checkpoint_path = os.path.join(checkpoint_path, '{net}-{epoch}-{type}.pth')\n","\n","best_acc = 0.0\n","for epoch in range(1, EPOCH):\n","    if epoch > warm:\n","        train_scheduler.step(epoch)\n","\n","    train(epoch)\n","    acc = eval_training(epoch)\n","\n","    #start to save best performance model after learning rate decay to 0.01 \n","    if epoch > MILESTONES[1] and best_acc < acc:\n","        torch.save(net.state_dict(), checkpoint_path.format(net=\"MobileNet\", epoch=epoch, type='best'))\n","        best_acc = acc\n","        continue\n","\n","    if not epoch % SAVE_EPOCH:\n","        torch.save(net.state_dict(), checkpoint_path.format(net=\"MobileNet\", epoch=epoch, type='regular'))\n","print('Training Finish')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[ 1 epoch]\n","Test set: Average loss: 0.0632, Accuracy: 0.0849\n","\n","[ 2 epoch]\n","Test set: Average loss: 0.0589, Accuracy: 0.1166\n","\n","[ 3 epoch]\n","Test set: Average loss: 0.0580, Accuracy: 0.1243\n","\n","[ 4 epoch]\n","Test set: Average loss: 0.0575, Accuracy: 0.1279\n","\n","[ 5 epoch]\n","Test set: Average loss: 0.0571, Accuracy: 0.1322\n","\n","[ 6 epoch]\n","Test set: Average loss: 0.0568, Accuracy: 0.1360\n","\n","[ 7 epoch]\n","Test set: Average loss: 0.0564, Accuracy: 0.1398\n","\n","[ 8 epoch]\n","Test set: Average loss: 0.0562, Accuracy: 0.1420\n","\n","[ 9 epoch]\n","Test set: Average loss: 0.0557, Accuracy: 0.1441\n","\n","[ 10 epoch]\n","Test set: Average loss: 0.0555, Accuracy: 0.1506\n","\n","[ 11 epoch]\n","Test set: Average loss: 0.0552, Accuracy: 0.1559\n","\n","[ 12 epoch]\n","Test set: Average loss: 0.0549, Accuracy: 0.1568\n","\n","[ 13 epoch]\n","Test set: Average loss: 0.0548, Accuracy: 0.1542\n","\n","[ 14 epoch]\n","Test set: Average loss: 0.0543, Accuracy: 0.1590\n","\n","[ 15 epoch]\n","Test set: Average loss: 0.0540, Accuracy: 0.1617\n","\n","[ 16 epoch]\n","Test set: Average loss: 0.0538, Accuracy: 0.1660\n","\n","[ 17 epoch]\n","Test set: Average loss: 0.0534, Accuracy: 0.1695\n","\n","[ 18 epoch]\n","Test set: Average loss: 0.0533, Accuracy: 0.1711\n","\n","[ 19 epoch]\n","Test set: Average loss: 0.0529, Accuracy: 0.1769\n","\n","[ 20 epoch]\n","Test set: Average loss: 0.0526, Accuracy: 0.1826\n","\n","[ 21 epoch]\n","Test set: Average loss: 0.0526, Accuracy: 0.1804\n","\n","[ 22 epoch]\n","Test set: Average loss: 0.0520, Accuracy: 0.1857\n","\n","[ 23 epoch]\n","Test set: Average loss: 0.0517, Accuracy: 0.1899\n","\n","[ 24 epoch]\n","Test set: Average loss: 0.0516, Accuracy: 0.1932\n","\n","[ 25 epoch]\n","Test set: Average loss: 0.0512, Accuracy: 0.2016\n","\n","[ 26 epoch]\n","Test set: Average loss: 0.0508, Accuracy: 0.2030\n","\n","[ 27 epoch]\n","Test set: Average loss: 0.0505, Accuracy: 0.2082\n","\n","[ 28 epoch]\n","Test set: Average loss: 0.0501, Accuracy: 0.2126\n","\n","[ 29 epoch]\n","Test set: Average loss: 0.0498, Accuracy: 0.2178\n","\n","[ 30 epoch]\n","Test set: Average loss: 0.0494, Accuracy: 0.2256\n","\n","[ 31 epoch]\n","Test set: Average loss: 0.0492, Accuracy: 0.2246\n","\n","[ 32 epoch]\n","Test set: Average loss: 0.0489, Accuracy: 0.2342\n","\n","[ 33 epoch]\n","Test set: Average loss: 0.0484, Accuracy: 0.2368\n","\n","[ 34 epoch]\n","Test set: Average loss: 0.0480, Accuracy: 0.2427\n","\n","[ 35 epoch]\n","Test set: Average loss: 0.0476, Accuracy: 0.2484\n","\n","[ 36 epoch]\n","Test set: Average loss: 0.0472, Accuracy: 0.2545\n","\n","[ 37 epoch]\n","Test set: Average loss: 0.0469, Accuracy: 0.2547\n","\n","[ 38 epoch]\n","Test set: Average loss: 0.0468, Accuracy: 0.2585\n","\n","[ 39 epoch]\n","Test set: Average loss: 0.0464, Accuracy: 0.2649\n","\n","[ 40 epoch]\n","Test set: Average loss: 0.0460, Accuracy: 0.2669\n","\n","[ 41 epoch]\n","Test set: Average loss: 0.0458, Accuracy: 0.2723\n","\n","[ 42 epoch]\n","Test set: Average loss: 0.0453, Accuracy: 0.2771\n","\n","[ 43 epoch]\n","Test set: Average loss: 0.0448, Accuracy: 0.2835\n","\n","[ 44 epoch]\n","Test set: Average loss: 0.0446, Accuracy: 0.2875\n","\n","[ 45 epoch]\n","Test set: Average loss: 0.0445, Accuracy: 0.2922\n","\n","[ 46 epoch]\n","Test set: Average loss: 0.0439, Accuracy: 0.2952\n","\n","[ 47 epoch]\n","Test set: Average loss: 0.0437, Accuracy: 0.3030\n","\n","[ 48 epoch]\n","Test set: Average loss: 0.0434, Accuracy: 0.3025\n","\n","[ 49 epoch]\n","Test set: Average loss: 0.0428, Accuracy: 0.3108\n","\n","[ 50 epoch]\n","Test set: Average loss: 0.0429, Accuracy: 0.3110\n","\n","[ 51 epoch]\n","Test set: Average loss: 0.0422, Accuracy: 0.3161\n","\n","[ 52 epoch]\n","Test set: Average loss: 0.0420, Accuracy: 0.3247\n","\n","[ 53 epoch]\n","Test set: Average loss: 0.0416, Accuracy: 0.3281\n","\n","[ 54 epoch]\n","Test set: Average loss: 0.0412, Accuracy: 0.3327\n","\n","[ 55 epoch]\n","Test set: Average loss: 0.0410, Accuracy: 0.3352\n","\n","[ 56 epoch]\n","Test set: Average loss: 0.0409, Accuracy: 0.3373\n","\n","[ 57 epoch]\n","Test set: Average loss: 0.0405, Accuracy: 0.3371\n","\n","[ 58 epoch]\n","Test set: Average loss: 0.0400, Accuracy: 0.3474\n","\n","[ 59 epoch]\n","Test set: Average loss: 0.0399, Accuracy: 0.3486\n","\n","[ 60 epoch]\n","Test set: Average loss: 0.0398, Accuracy: 0.3498\n","\n","[ 61 epoch]\n","Test set: Average loss: 0.0396, Accuracy: 0.3528\n","\n","[ 62 epoch]\n","Test set: Average loss: 0.0392, Accuracy: 0.3568\n","\n","[ 63 epoch]\n","Test set: Average loss: 0.0392, Accuracy: 0.3560\n","\n","[ 64 epoch]\n","Test set: Average loss: 0.0389, Accuracy: 0.3648\n","\n","[ 65 epoch]\n","Test set: Average loss: 0.0382, Accuracy: 0.3703\n","\n","[ 66 epoch]\n","Test set: Average loss: 0.0383, Accuracy: 0.3709\n","\n","[ 67 epoch]\n","Test set: Average loss: 0.0378, Accuracy: 0.3790\n","\n","[ 68 epoch]\n","Test set: Average loss: 0.0377, Accuracy: 0.3801\n","\n","[ 69 epoch]\n","Test set: Average loss: 0.0374, Accuracy: 0.3795\n","\n","[ 70 epoch]\n","Test set: Average loss: 0.0374, Accuracy: 0.3816\n","\n","[ 71 epoch]\n","Test set: Average loss: 0.0371, Accuracy: 0.3924\n","\n","[ 72 epoch]\n","Test set: Average loss: 0.0372, Accuracy: 0.3923\n","\n","[ 73 epoch]\n","Test set: Average loss: 0.0367, Accuracy: 0.3970\n","\n","[ 74 epoch]\n","Test set: Average loss: 0.0366, Accuracy: 0.3966\n","\n","[ 75 epoch]\n","Test set: Average loss: 0.0366, Accuracy: 0.3982\n","\n","[ 76 epoch]\n","Test set: Average loss: 0.0368, Accuracy: 0.3986\n","\n","[ 77 epoch]\n","Test set: Average loss: 0.0363, Accuracy: 0.4049\n","\n","[ 78 epoch]\n","Test set: Average loss: 0.0362, Accuracy: 0.4021\n","\n","[ 79 epoch]\n","Test set: Average loss: 0.0359, Accuracy: 0.4110\n","\n","[ 80 epoch]\n","Test set: Average loss: 0.0356, Accuracy: 0.4161\n","\n","[ 81 epoch]\n","Test set: Average loss: 0.0360, Accuracy: 0.4093\n","\n","[ 82 epoch]\n","Test set: Average loss: 0.0356, Accuracy: 0.4100\n","\n","[ 83 epoch]\n","Test set: Average loss: 0.0356, Accuracy: 0.4157\n","\n","[ 84 epoch]\n","Test set: Average loss: 0.0352, Accuracy: 0.4201\n","\n","[ 85 epoch]\n","Test set: Average loss: 0.0351, Accuracy: 0.4261\n","\n","[ 86 epoch]\n","Test set: Average loss: 0.0350, Accuracy: 0.4249\n","\n","[ 87 epoch]\n","Test set: Average loss: 0.0351, Accuracy: 0.4225\n","\n","[ 88 epoch]\n","Test set: Average loss: 0.0351, Accuracy: 0.4209\n","\n","[ 89 epoch]\n","Test set: Average loss: 0.0349, Accuracy: 0.4268\n","\n","[ 90 epoch]\n","Test set: Average loss: 0.0349, Accuracy: 0.4296\n","\n","[ 91 epoch]\n","Test set: Average loss: 0.0348, Accuracy: 0.4324\n","\n","[ 92 epoch]\n","Test set: Average loss: 0.0347, Accuracy: 0.4343\n","\n","[ 93 epoch]\n","Test set: Average loss: 0.0344, Accuracy: 0.4361\n","\n","[ 94 epoch]\n","Test set: Average loss: 0.0343, Accuracy: 0.4355\n","\n","[ 95 epoch]\n","Test set: Average loss: 0.0344, Accuracy: 0.4397\n","\n","[ 96 epoch]\n","Test set: Average loss: 0.0342, Accuracy: 0.4389\n","\n","[ 97 epoch]\n","Test set: Average loss: 0.0344, Accuracy: 0.4370\n","\n","[ 98 epoch]\n","Test set: Average loss: 0.0345, Accuracy: 0.4378\n","\n","[ 99 epoch]\n","Test set: Average loss: 0.0346, Accuracy: 0.4319\n","\n","Training Finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ds9IEmvluhN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}