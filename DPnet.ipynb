{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "peleenet_shuffle_효희수정.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85de0a64bc2c4dc09b6c25fc9ba4321c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74948ea45c684907964df628a20b917e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7de8881d80b54687adc4d80c784553c2",
              "IPY_MODEL_0aec7010085f4b9dbdc42cb18d1e8b14"
            ]
          }
        },
        "74948ea45c684907964df628a20b917e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7de8881d80b54687adc4d80c784553c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92148f01337c44f69d8607e98c0ddcdc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d75c7bf88c074858a36c4e9597ab10c5"
          }
        },
        "0aec7010085f4b9dbdc42cb18d1e8b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81ec3620dd744a7c94aab30c355373ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:08&lt;00:00, 21121433.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d9af4d086244a308157c7c7ac2e65a7"
          }
        },
        "92148f01337c44f69d8607e98c0ddcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d75c7bf88c074858a36c4e9597ab10c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81ec3620dd744a7c94aab30c355373ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d9af4d086244a308157c7c7ac2e65a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ADmd5s8GDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from torch.utils import data as D\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import torchsummary\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "############### Miok ############\n",
        "\n",
        "import io\n",
        "#import torch.onnx\n",
        "#import onnx\n",
        "#import onnxruntime as ort\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTM6ZIb78Q6J",
        "colab_type": "code",
        "outputId": "125e1326-ca95-4c0f-eac2-0d61b342fa4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(torch.__version__)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLJ3Oyz8TOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "validation_ratio = 0.1\n",
        "random_seed = 10\n",
        "initial_lr = 0.1\n",
        "num_epoch = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgTHhVYO8Upr",
        "colab_type": "code",
        "outputId": "94d802f3-7647-4c5c-fe33-c664b6951edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "85de0a64bc2c4dc09b6c25fc9ba4321c",
            "74948ea45c684907964df628a20b917e",
            "7de8881d80b54687adc4d80c784553c2",
            "0aec7010085f4b9dbdc42cb18d1e8b14",
            "92148f01337c44f69d8607e98c0ddcdc",
            "d75c7bf88c074858a36c4e9597ab10c5",
            "81ec3620dd744a7c94aab30c355373ad",
            "1d9af4d086244a308157c7c7ac2e65a7"
          ]
        }
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "transform_validation = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize(224),     \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "validset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_validation)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "num_train = len(trainset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(validation_ratio * num_train))\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
        ")\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85de0a64bc2c4dc09b6c25fc9ba4321c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zw7FVrAB2OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class conv_bn_relu(nn.Module):\n",
        "    def __init__(self, nin, nout, kernel_size, stride, padding,groups=1, bias=False):\n",
        "        super(conv_bn_relu, self).__init__()\n",
        "        self.conv = nn.Conv2d(nin, nout, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups,bias=bias)\n",
        "        self.batch_norm = nn.BatchNorm2d(nout)\n",
        "        self.relu = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WKIOixwke-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dw_block(nn.Module):\n",
        "    def __init__(self, nin, kernel_size, padding=1, bias=False, stride=1):\n",
        "        super(dw_block, self).__init__()\n",
        "        self.dw_block = nn.Sequential(\n",
        "            nn.Conv2d(nin, nin, kernel_size=kernel_size, stride=stride, padding=padding, groups=nin, bias=bias),\n",
        "            nn.BatchNorm2d(nin),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "       \n",
        "    def forward(self, x):\n",
        "        out = self.dw_block(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtM2mOjB7Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transition_layer(nn.Sequential):\n",
        "  def __init__(self, nin, theta=1):    \n",
        "      super(Transition_layer, self).__init__()\n",
        "      \n",
        "      self.add_module('conv_1x1', conv_bn_relu(nin=nin, nout=int(nin*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
        "      self.add_module('avg_pool_2x2', nn.AvgPool2d(kernel_size=2, stride=2, padding=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSsHrN_FRZX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################## Miok\n",
        "class ShuffleBlock(nn.Module):\n",
        "    def __init__(self, groups):\n",
        "        super(ShuffleBlock, self).__init__()\n",
        "        self.groups = groups\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]'''\n",
        "        N,C,H,W = x.size()\n",
        "        g = self.groups\n",
        "        return x.view(N,g,C//g,H,W).permute(0,2,1,3,4).reshape(N,C,H,W)\n",
        "############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufk3BSK4B-d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StemBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StemBlock, self).__init__()\n",
        "        \n",
        "        self.conv_3x3_first = dw_block(nin=3, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.conv_3x3_first_pw = conv_bn_relu(nin=3, nout=32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        \n",
        "\n",
        "        self.conv_1x1_left = conv_bn_relu(groups=4,nin=32, nout=16, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.shuffle1 = ShuffleBlock(groups=4)\n",
        "\n",
        "        self.conv_3x3_left = dw_block(nin=16, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.conv_3x3_left_pw = conv_bn_relu(groups=4, nin=16, nout=32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        \n",
        "        self.max_pool_right = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        self.conv_1x1_last = conv_bn_relu(groups=4,nin=64, nout=32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_first = self.conv_3x3_first(x)\n",
        "        out_first = self.conv_3x3_first_pw(out_first)\n",
        "\n",
        "        out_left = self.conv_1x1_left(out_first)\n",
        "        out_left = self.shuffle1(out_left)\n",
        "        out_left = self.conv_3x3_left(out_left)\n",
        "        out_left = self.conv_3x3_left_pw(out_left)\n",
        "\n",
        "        out_right = self.max_pool_right(out_first)\n",
        "        \n",
        "        out_middle = torch.cat((out_left, out_right), 1)\n",
        "        \n",
        "        out_last = self.conv_1x1_last(out_middle)\n",
        "                \n",
        "        return out_last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsIhda3TCCTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dense_layer(nn.Module):\n",
        "  def __init__(self, nin, growth_rate, drop_rate=0.2):    \n",
        "      super(dense_layer, self).__init__()\n",
        "      \n",
        "      self.dense_left_way = nn.Sequential()\n",
        "      \n",
        "      self.dense_left_way.add_module('conv_1x1', conv_bn_relu(groups=4,nin=nin, nout=growth_rate*2, kernel_size=1, stride=1, padding=0, bias=False))\n",
        "\n",
        "      self.dense_left_way.add_module('conv_3x3', dw_block(nin=growth_rate*2, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "      self.dense_left_way.add_module('conv_3x3_pw', conv_bn_relu(groups=4, nin=growth_rate*2, nout=growth_rate//2, kernel_size=1, stride=1, padding=0, bias=False))\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "      self.dense_right_way = nn.Sequential()\n",
        "      \n",
        "      self.dense_right_way.add_module('conv_1x1', conv_bn_relu(groups=4,nin=nin, nout=growth_rate*2, kernel_size=1, stride=1, padding=0, bias=False))\n",
        "      #self.dense_right_way.add_module('shuffle3', ShuffleBlock(groups=8))\n",
        "      \n",
        "      self.dense_right_way.add_module('conv_3x3_1', dw_block(nin=growth_rate*2,kernel_size=3, stride=1, padding=1, bias=False))\n",
        "      self.dense_right_way.add_module('conv_3x3_1_pw', conv_bn_relu(groups=4, nin=growth_rate*2, nout=growth_rate//2, kernel_size=1, stride=1, padding=0, bias=False))\n",
        "     # self.dense_right_way.add_module('shuffle4', ShuffleBlock(groups=8))\n",
        "     \n",
        "\n",
        "      self.dense_right_way.add_module('conv_3x3 2', dw_block(nin=growth_rate//2, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "      self.dense_right_way.add_module('conv_3x3_2_pw', conv_bn_relu(groups=4,nin=growth_rate//2, nout=growth_rate//2, kernel_size=1, stride=1, padding=0, bias=False))\n",
        "     # self.dense_right_way.add_module('shuffle4', ShuffleBlock(groups=8))\n",
        "     \n",
        "  \n",
        "\n",
        "      self.drop_rate = drop_rate\n",
        "      \n",
        "  def forward(self, x):\n",
        "      left_output = self.dense_left_way(x)\n",
        "      right_output = self.dense_right_way(x)\n",
        "\n",
        "      if self.drop_rate > 0:\n",
        "          left_output = F.dropout(left_output, p=self.drop_rate, training=self.training)\n",
        "          right_output = F.dropout(right_output, p=self.drop_rate, training=self.training)\n",
        "          \n",
        "      dense_layer_output = torch.cat((x, left_output, right_output), 1)\n",
        "            \n",
        "      return dense_layer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Aofx5_CFmx",
        "colab_type": "code",
        "outputId": "7dacbb95-5e25-44a0-e6de-5abbb2e859de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class DenseBlock(nn.Sequential):\n",
        "  def __init__(self, nin, num_dense_layers, growth_rate, drop_rate=0.0):\n",
        "      super(DenseBlock, self).__init__()\n",
        "                        \n",
        "      for i in range(num_dense_layers):\n",
        "          nin_dense_layer = nin + growth_rate * i\n",
        "          self.add_module('dense_layer_%d' % i, dense_layer(nin=nin_dense_layer, growth_rate=growth_rate, drop_rate=drop_rate))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XX3g7PoCIEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PeleeNet(nn.Module):\n",
        "    def __init__(self, growth_rate=32, num_dense_layers=[3,4,8,6], theta=1, drop_rate=0.0, num_classes=10):\n",
        "        super(PeleeNet, self).__init__()\n",
        "        \n",
        "        assert len(num_dense_layers) == 4\n",
        "        \n",
        "        self.features = nn.Sequential()\n",
        "        self.features.add_module('StemBlock', StemBlock())\n",
        "        \n",
        "        nin_transition_layer = 32\n",
        "        \n",
        "        for i in range(len(num_dense_layers)):\n",
        "            self.features.add_module('DenseBlock_%d' % (i+1), DenseBlock(nin=nin_transition_layer, num_dense_layers=num_dense_layers[i], growth_rate=growth_rate, drop_rate=0.0))\n",
        "            nin_transition_layer +=  num_dense_layers[i] * growth_rate\n",
        "            \n",
        "            if i == len(num_dense_layers) - 1:\n",
        "                self.features.add_module('Transition_layer_%d' % (i+1), conv_bn_relu(nin=nin_transition_layer, nout=int(nin_transition_layer*theta), kernel_size=1, stride=1, padding=0, bias=False))\n",
        "            else:\n",
        "                self.features.add_module('Transition_layer_%d' % (i+1), Transition_layer(nin=nin_transition_layer, theta=1))\n",
        "        \n",
        "        #self.linear = nn.Linear(nin_transition_layer, num_classes)\n",
        "        self.fc_v2 = nn.Conv2d(704, num_classes, 1, 1, groups=2)\n",
        "    def forward(self, x):\n",
        "        stage_output = self.features(x)\n",
        "        \n",
        "        global_avg_pool_output = F.adaptive_avg_pool2d(stage_output, (1, 1))  \n",
        "        output = self.fc_v2(global_avg_pool_output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeqihwOyCNYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = PeleeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAo94t0hCWZV",
        "colab_type": "code",
        "outputId": "7ad11137-6d81-406e-b2e3-41268d3ff552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeleeNet(\n",
              "  (features): Sequential(\n",
              "    (StemBlock): StemBlock(\n",
              "      (conv_3x3_first): dw_block(\n",
              "        (dw_block): Sequential(\n",
              "          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
              "          (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv_3x3_first_pw): conv_bn_relu(\n",
              "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (conv_1x1_left): conv_bn_relu(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "        (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (shuffle1): ShuffleBlock()\n",
              "      (conv_3x3_left): dw_block(\n",
              "        (dw_block): Sequential(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv_3x3_left_pw): conv_bn_relu(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (max_pool_right): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv_1x1_last): conv_bn_relu(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "        (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (DenseBlock_1): DenseBlock(\n",
              "      (dense_layer_0): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_1): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_2): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (Transition_layer_1): Transition_layer(\n",
              "      (conv_1x1): conv_bn_relu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (DenseBlock_2): DenseBlock(\n",
              "      (dense_layer_0): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_1): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_2): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_3): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(224, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(224, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (Transition_layer_2): Transition_layer(\n",
              "      (conv_1x1): conv_bn_relu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (DenseBlock_3): DenseBlock(\n",
              "      (dense_layer_0): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_1): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_2): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_3): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(352, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_4): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_5): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(416, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(416, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_6): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(448, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_7): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (Transition_layer_3): Transition_layer(\n",
              "      (conv_1x1): conv_bn_relu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (DenseBlock_4): DenseBlock(\n",
              "      (dense_layer_0): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_1): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(544, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(544, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_2): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_3): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(608, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(608, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_4): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dense_layer_5): dense_layer(\n",
              "        (dense_left_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(672, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (dense_right_way): Sequential(\n",
              "          (conv_1x1): conv_bn_relu(\n",
              "            (conv): Conv2d(672, 64, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3_1): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_1_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv_3x3 2): dw_block(\n",
              "            (dw_block): Sequential(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (conv_3x3_2_pw): conv_bn_relu(\n",
              "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "            (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (Transition_layer_4): conv_bn_relu(\n",
              "      (conv): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (fc_v2): Conv2d(704, 10, kernel_size=(1, 1), stride=(1, 1), groups=2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4DMGPzCYBO",
        "colab_type": "code",
        "outputId": "5380634a-d6c1-46c8-99f5-47a3c249cb22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "torchsummary.summary(net, (3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 3, 112, 112]              27\n",
            "       BatchNorm2d-2          [-1, 3, 112, 112]               6\n",
            "              ReLU-3          [-1, 3, 112, 112]               0\n",
            "          dw_block-4          [-1, 3, 112, 112]               0\n",
            "            Conv2d-5         [-1, 32, 112, 112]              96\n",
            "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
            "              ReLU-7         [-1, 32, 112, 112]               0\n",
            "      conv_bn_relu-8         [-1, 32, 112, 112]               0\n",
            "            Conv2d-9         [-1, 16, 112, 112]             128\n",
            "      BatchNorm2d-10         [-1, 16, 112, 112]              32\n",
            "             ReLU-11         [-1, 16, 112, 112]               0\n",
            "     conv_bn_relu-12         [-1, 16, 112, 112]               0\n",
            "     ShuffleBlock-13         [-1, 16, 112, 112]               0\n",
            "           Conv2d-14           [-1, 16, 56, 56]             144\n",
            "      BatchNorm2d-15           [-1, 16, 56, 56]              32\n",
            "             ReLU-16           [-1, 16, 56, 56]               0\n",
            "         dw_block-17           [-1, 16, 56, 56]               0\n",
            "           Conv2d-18           [-1, 32, 56, 56]             128\n",
            "      BatchNorm2d-19           [-1, 32, 56, 56]              64\n",
            "             ReLU-20           [-1, 32, 56, 56]               0\n",
            "     conv_bn_relu-21           [-1, 32, 56, 56]               0\n",
            "        MaxPool2d-22           [-1, 32, 56, 56]               0\n",
            "           Conv2d-23           [-1, 32, 56, 56]             512\n",
            "      BatchNorm2d-24           [-1, 32, 56, 56]              64\n",
            "             ReLU-25           [-1, 32, 56, 56]               0\n",
            "     conv_bn_relu-26           [-1, 32, 56, 56]               0\n",
            "        StemBlock-27           [-1, 32, 56, 56]               0\n",
            "           Conv2d-28           [-1, 64, 56, 56]             512\n",
            "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
            "             ReLU-30           [-1, 64, 56, 56]               0\n",
            "     conv_bn_relu-31           [-1, 64, 56, 56]               0\n",
            "           Conv2d-32           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-33           [-1, 64, 56, 56]             128\n",
            "             ReLU-34           [-1, 64, 56, 56]               0\n",
            "         dw_block-35           [-1, 64, 56, 56]               0\n",
            "           Conv2d-36           [-1, 16, 56, 56]             256\n",
            "      BatchNorm2d-37           [-1, 16, 56, 56]              32\n",
            "             ReLU-38           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-39           [-1, 16, 56, 56]               0\n",
            "           Conv2d-40           [-1, 64, 56, 56]             512\n",
            "      BatchNorm2d-41           [-1, 64, 56, 56]             128\n",
            "             ReLU-42           [-1, 64, 56, 56]               0\n",
            "     conv_bn_relu-43           [-1, 64, 56, 56]               0\n",
            "           Conv2d-44           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-45           [-1, 64, 56, 56]             128\n",
            "             ReLU-46           [-1, 64, 56, 56]               0\n",
            "         dw_block-47           [-1, 64, 56, 56]               0\n",
            "           Conv2d-48           [-1, 16, 56, 56]             256\n",
            "      BatchNorm2d-49           [-1, 16, 56, 56]              32\n",
            "             ReLU-50           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-51           [-1, 16, 56, 56]               0\n",
            "           Conv2d-52           [-1, 16, 56, 56]             144\n",
            "      BatchNorm2d-53           [-1, 16, 56, 56]              32\n",
            "             ReLU-54           [-1, 16, 56, 56]               0\n",
            "         dw_block-55           [-1, 16, 56, 56]               0\n",
            "           Conv2d-56           [-1, 16, 56, 56]              64\n",
            "      BatchNorm2d-57           [-1, 16, 56, 56]              32\n",
            "             ReLU-58           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-59           [-1, 16, 56, 56]               0\n",
            "      dense_layer-60           [-1, 64, 56, 56]               0\n",
            "           Conv2d-61           [-1, 64, 56, 56]           1,024\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "     conv_bn_relu-64           [-1, 64, 56, 56]               0\n",
            "           Conv2d-65           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-66           [-1, 64, 56, 56]             128\n",
            "             ReLU-67           [-1, 64, 56, 56]               0\n",
            "         dw_block-68           [-1, 64, 56, 56]               0\n",
            "           Conv2d-69           [-1, 16, 56, 56]             256\n",
            "      BatchNorm2d-70           [-1, 16, 56, 56]              32\n",
            "             ReLU-71           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-72           [-1, 16, 56, 56]               0\n",
            "           Conv2d-73           [-1, 64, 56, 56]           1,024\n",
            "      BatchNorm2d-74           [-1, 64, 56, 56]             128\n",
            "             ReLU-75           [-1, 64, 56, 56]               0\n",
            "     conv_bn_relu-76           [-1, 64, 56, 56]               0\n",
            "           Conv2d-77           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-78           [-1, 64, 56, 56]             128\n",
            "             ReLU-79           [-1, 64, 56, 56]               0\n",
            "         dw_block-80           [-1, 64, 56, 56]               0\n",
            "           Conv2d-81           [-1, 16, 56, 56]             256\n",
            "      BatchNorm2d-82           [-1, 16, 56, 56]              32\n",
            "             ReLU-83           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-84           [-1, 16, 56, 56]               0\n",
            "           Conv2d-85           [-1, 16, 56, 56]             144\n",
            "      BatchNorm2d-86           [-1, 16, 56, 56]              32\n",
            "             ReLU-87           [-1, 16, 56, 56]               0\n",
            "         dw_block-88           [-1, 16, 56, 56]               0\n",
            "           Conv2d-89           [-1, 16, 56, 56]              64\n",
            "      BatchNorm2d-90           [-1, 16, 56, 56]              32\n",
            "             ReLU-91           [-1, 16, 56, 56]               0\n",
            "     conv_bn_relu-92           [-1, 16, 56, 56]               0\n",
            "      dense_layer-93           [-1, 96, 56, 56]               0\n",
            "           Conv2d-94           [-1, 64, 56, 56]           1,536\n",
            "      BatchNorm2d-95           [-1, 64, 56, 56]             128\n",
            "             ReLU-96           [-1, 64, 56, 56]               0\n",
            "     conv_bn_relu-97           [-1, 64, 56, 56]               0\n",
            "           Conv2d-98           [-1, 64, 56, 56]             576\n",
            "      BatchNorm2d-99           [-1, 64, 56, 56]             128\n",
            "            ReLU-100           [-1, 64, 56, 56]               0\n",
            "        dw_block-101           [-1, 64, 56, 56]               0\n",
            "          Conv2d-102           [-1, 16, 56, 56]             256\n",
            "     BatchNorm2d-103           [-1, 16, 56, 56]              32\n",
            "            ReLU-104           [-1, 16, 56, 56]               0\n",
            "    conv_bn_relu-105           [-1, 16, 56, 56]               0\n",
            "          Conv2d-106           [-1, 64, 56, 56]           1,536\n",
            "     BatchNorm2d-107           [-1, 64, 56, 56]             128\n",
            "            ReLU-108           [-1, 64, 56, 56]               0\n",
            "    conv_bn_relu-109           [-1, 64, 56, 56]               0\n",
            "          Conv2d-110           [-1, 64, 56, 56]             576\n",
            "     BatchNorm2d-111           [-1, 64, 56, 56]             128\n",
            "            ReLU-112           [-1, 64, 56, 56]               0\n",
            "        dw_block-113           [-1, 64, 56, 56]               0\n",
            "          Conv2d-114           [-1, 16, 56, 56]             256\n",
            "     BatchNorm2d-115           [-1, 16, 56, 56]              32\n",
            "            ReLU-116           [-1, 16, 56, 56]               0\n",
            "    conv_bn_relu-117           [-1, 16, 56, 56]               0\n",
            "          Conv2d-118           [-1, 16, 56, 56]             144\n",
            "     BatchNorm2d-119           [-1, 16, 56, 56]              32\n",
            "            ReLU-120           [-1, 16, 56, 56]               0\n",
            "        dw_block-121           [-1, 16, 56, 56]               0\n",
            "          Conv2d-122           [-1, 16, 56, 56]              64\n",
            "     BatchNorm2d-123           [-1, 16, 56, 56]              32\n",
            "            ReLU-124           [-1, 16, 56, 56]               0\n",
            "    conv_bn_relu-125           [-1, 16, 56, 56]               0\n",
            "     dense_layer-126          [-1, 128, 56, 56]               0\n",
            "          Conv2d-127          [-1, 128, 56, 56]          16,384\n",
            "     BatchNorm2d-128          [-1, 128, 56, 56]             256\n",
            "            ReLU-129          [-1, 128, 56, 56]               0\n",
            "    conv_bn_relu-130          [-1, 128, 56, 56]               0\n",
            "       AvgPool2d-131          [-1, 128, 28, 28]               0\n",
            "          Conv2d-132           [-1, 64, 28, 28]           2,048\n",
            "     BatchNorm2d-133           [-1, 64, 28, 28]             128\n",
            "            ReLU-134           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-135           [-1, 64, 28, 28]               0\n",
            "          Conv2d-136           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-137           [-1, 64, 28, 28]             128\n",
            "            ReLU-138           [-1, 64, 28, 28]               0\n",
            "        dw_block-139           [-1, 64, 28, 28]               0\n",
            "          Conv2d-140           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-141           [-1, 16, 28, 28]              32\n",
            "            ReLU-142           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-143           [-1, 16, 28, 28]               0\n",
            "          Conv2d-144           [-1, 64, 28, 28]           2,048\n",
            "     BatchNorm2d-145           [-1, 64, 28, 28]             128\n",
            "            ReLU-146           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-147           [-1, 64, 28, 28]               0\n",
            "          Conv2d-148           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-149           [-1, 64, 28, 28]             128\n",
            "            ReLU-150           [-1, 64, 28, 28]               0\n",
            "        dw_block-151           [-1, 64, 28, 28]               0\n",
            "          Conv2d-152           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-153           [-1, 16, 28, 28]              32\n",
            "            ReLU-154           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-155           [-1, 16, 28, 28]               0\n",
            "          Conv2d-156           [-1, 16, 28, 28]             144\n",
            "     BatchNorm2d-157           [-1, 16, 28, 28]              32\n",
            "            ReLU-158           [-1, 16, 28, 28]               0\n",
            "        dw_block-159           [-1, 16, 28, 28]               0\n",
            "          Conv2d-160           [-1, 16, 28, 28]              64\n",
            "     BatchNorm2d-161           [-1, 16, 28, 28]              32\n",
            "            ReLU-162           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-163           [-1, 16, 28, 28]               0\n",
            "     dense_layer-164          [-1, 160, 28, 28]               0\n",
            "          Conv2d-165           [-1, 64, 28, 28]           2,560\n",
            "     BatchNorm2d-166           [-1, 64, 28, 28]             128\n",
            "            ReLU-167           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-168           [-1, 64, 28, 28]               0\n",
            "          Conv2d-169           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-170           [-1, 64, 28, 28]             128\n",
            "            ReLU-171           [-1, 64, 28, 28]               0\n",
            "        dw_block-172           [-1, 64, 28, 28]               0\n",
            "          Conv2d-173           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-174           [-1, 16, 28, 28]              32\n",
            "            ReLU-175           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-176           [-1, 16, 28, 28]               0\n",
            "          Conv2d-177           [-1, 64, 28, 28]           2,560\n",
            "     BatchNorm2d-178           [-1, 64, 28, 28]             128\n",
            "            ReLU-179           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-180           [-1, 64, 28, 28]               0\n",
            "          Conv2d-181           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-182           [-1, 64, 28, 28]             128\n",
            "            ReLU-183           [-1, 64, 28, 28]               0\n",
            "        dw_block-184           [-1, 64, 28, 28]               0\n",
            "          Conv2d-185           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-186           [-1, 16, 28, 28]              32\n",
            "            ReLU-187           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-188           [-1, 16, 28, 28]               0\n",
            "          Conv2d-189           [-1, 16, 28, 28]             144\n",
            "     BatchNorm2d-190           [-1, 16, 28, 28]              32\n",
            "            ReLU-191           [-1, 16, 28, 28]               0\n",
            "        dw_block-192           [-1, 16, 28, 28]               0\n",
            "          Conv2d-193           [-1, 16, 28, 28]              64\n",
            "     BatchNorm2d-194           [-1, 16, 28, 28]              32\n",
            "            ReLU-195           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-196           [-1, 16, 28, 28]               0\n",
            "     dense_layer-197          [-1, 192, 28, 28]               0\n",
            "          Conv2d-198           [-1, 64, 28, 28]           3,072\n",
            "     BatchNorm2d-199           [-1, 64, 28, 28]             128\n",
            "            ReLU-200           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-201           [-1, 64, 28, 28]               0\n",
            "          Conv2d-202           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-203           [-1, 64, 28, 28]             128\n",
            "            ReLU-204           [-1, 64, 28, 28]               0\n",
            "        dw_block-205           [-1, 64, 28, 28]               0\n",
            "          Conv2d-206           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-207           [-1, 16, 28, 28]              32\n",
            "            ReLU-208           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-209           [-1, 16, 28, 28]               0\n",
            "          Conv2d-210           [-1, 64, 28, 28]           3,072\n",
            "     BatchNorm2d-211           [-1, 64, 28, 28]             128\n",
            "            ReLU-212           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-213           [-1, 64, 28, 28]               0\n",
            "          Conv2d-214           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-215           [-1, 64, 28, 28]             128\n",
            "            ReLU-216           [-1, 64, 28, 28]               0\n",
            "        dw_block-217           [-1, 64, 28, 28]               0\n",
            "          Conv2d-218           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-219           [-1, 16, 28, 28]              32\n",
            "            ReLU-220           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-221           [-1, 16, 28, 28]               0\n",
            "          Conv2d-222           [-1, 16, 28, 28]             144\n",
            "     BatchNorm2d-223           [-1, 16, 28, 28]              32\n",
            "            ReLU-224           [-1, 16, 28, 28]               0\n",
            "        dw_block-225           [-1, 16, 28, 28]               0\n",
            "          Conv2d-226           [-1, 16, 28, 28]              64\n",
            "     BatchNorm2d-227           [-1, 16, 28, 28]              32\n",
            "            ReLU-228           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-229           [-1, 16, 28, 28]               0\n",
            "     dense_layer-230          [-1, 224, 28, 28]               0\n",
            "          Conv2d-231           [-1, 64, 28, 28]           3,584\n",
            "     BatchNorm2d-232           [-1, 64, 28, 28]             128\n",
            "            ReLU-233           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-234           [-1, 64, 28, 28]               0\n",
            "          Conv2d-235           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-236           [-1, 64, 28, 28]             128\n",
            "            ReLU-237           [-1, 64, 28, 28]               0\n",
            "        dw_block-238           [-1, 64, 28, 28]               0\n",
            "          Conv2d-239           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-240           [-1, 16, 28, 28]              32\n",
            "            ReLU-241           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-242           [-1, 16, 28, 28]               0\n",
            "          Conv2d-243           [-1, 64, 28, 28]           3,584\n",
            "     BatchNorm2d-244           [-1, 64, 28, 28]             128\n",
            "            ReLU-245           [-1, 64, 28, 28]               0\n",
            "    conv_bn_relu-246           [-1, 64, 28, 28]               0\n",
            "          Conv2d-247           [-1, 64, 28, 28]             576\n",
            "     BatchNorm2d-248           [-1, 64, 28, 28]             128\n",
            "            ReLU-249           [-1, 64, 28, 28]               0\n",
            "        dw_block-250           [-1, 64, 28, 28]               0\n",
            "          Conv2d-251           [-1, 16, 28, 28]             256\n",
            "     BatchNorm2d-252           [-1, 16, 28, 28]              32\n",
            "            ReLU-253           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-254           [-1, 16, 28, 28]               0\n",
            "          Conv2d-255           [-1, 16, 28, 28]             144\n",
            "     BatchNorm2d-256           [-1, 16, 28, 28]              32\n",
            "            ReLU-257           [-1, 16, 28, 28]               0\n",
            "        dw_block-258           [-1, 16, 28, 28]               0\n",
            "          Conv2d-259           [-1, 16, 28, 28]              64\n",
            "     BatchNorm2d-260           [-1, 16, 28, 28]              32\n",
            "            ReLU-261           [-1, 16, 28, 28]               0\n",
            "    conv_bn_relu-262           [-1, 16, 28, 28]               0\n",
            "     dense_layer-263          [-1, 256, 28, 28]               0\n",
            "          Conv2d-264          [-1, 256, 28, 28]          65,536\n",
            "     BatchNorm2d-265          [-1, 256, 28, 28]             512\n",
            "            ReLU-266          [-1, 256, 28, 28]               0\n",
            "    conv_bn_relu-267          [-1, 256, 28, 28]               0\n",
            "       AvgPool2d-268          [-1, 256, 14, 14]               0\n",
            "          Conv2d-269           [-1, 64, 14, 14]           4,096\n",
            "     BatchNorm2d-270           [-1, 64, 14, 14]             128\n",
            "            ReLU-271           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-272           [-1, 64, 14, 14]               0\n",
            "          Conv2d-273           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-274           [-1, 64, 14, 14]             128\n",
            "            ReLU-275           [-1, 64, 14, 14]               0\n",
            "        dw_block-276           [-1, 64, 14, 14]               0\n",
            "          Conv2d-277           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-278           [-1, 16, 14, 14]              32\n",
            "            ReLU-279           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-280           [-1, 16, 14, 14]               0\n",
            "          Conv2d-281           [-1, 64, 14, 14]           4,096\n",
            "     BatchNorm2d-282           [-1, 64, 14, 14]             128\n",
            "            ReLU-283           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-284           [-1, 64, 14, 14]               0\n",
            "          Conv2d-285           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-286           [-1, 64, 14, 14]             128\n",
            "            ReLU-287           [-1, 64, 14, 14]               0\n",
            "        dw_block-288           [-1, 64, 14, 14]               0\n",
            "          Conv2d-289           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-290           [-1, 16, 14, 14]              32\n",
            "            ReLU-291           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-292           [-1, 16, 14, 14]               0\n",
            "          Conv2d-293           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-294           [-1, 16, 14, 14]              32\n",
            "            ReLU-295           [-1, 16, 14, 14]               0\n",
            "        dw_block-296           [-1, 16, 14, 14]               0\n",
            "          Conv2d-297           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-298           [-1, 16, 14, 14]              32\n",
            "            ReLU-299           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-300           [-1, 16, 14, 14]               0\n",
            "     dense_layer-301          [-1, 288, 14, 14]               0\n",
            "          Conv2d-302           [-1, 64, 14, 14]           4,608\n",
            "     BatchNorm2d-303           [-1, 64, 14, 14]             128\n",
            "            ReLU-304           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-305           [-1, 64, 14, 14]               0\n",
            "          Conv2d-306           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-307           [-1, 64, 14, 14]             128\n",
            "            ReLU-308           [-1, 64, 14, 14]               0\n",
            "        dw_block-309           [-1, 64, 14, 14]               0\n",
            "          Conv2d-310           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-311           [-1, 16, 14, 14]              32\n",
            "            ReLU-312           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-313           [-1, 16, 14, 14]               0\n",
            "          Conv2d-314           [-1, 64, 14, 14]           4,608\n",
            "     BatchNorm2d-315           [-1, 64, 14, 14]             128\n",
            "            ReLU-316           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-317           [-1, 64, 14, 14]               0\n",
            "          Conv2d-318           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-319           [-1, 64, 14, 14]             128\n",
            "            ReLU-320           [-1, 64, 14, 14]               0\n",
            "        dw_block-321           [-1, 64, 14, 14]               0\n",
            "          Conv2d-322           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-323           [-1, 16, 14, 14]              32\n",
            "            ReLU-324           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-325           [-1, 16, 14, 14]               0\n",
            "          Conv2d-326           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-327           [-1, 16, 14, 14]              32\n",
            "            ReLU-328           [-1, 16, 14, 14]               0\n",
            "        dw_block-329           [-1, 16, 14, 14]               0\n",
            "          Conv2d-330           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-331           [-1, 16, 14, 14]              32\n",
            "            ReLU-332           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-333           [-1, 16, 14, 14]               0\n",
            "     dense_layer-334          [-1, 320, 14, 14]               0\n",
            "          Conv2d-335           [-1, 64, 14, 14]           5,120\n",
            "     BatchNorm2d-336           [-1, 64, 14, 14]             128\n",
            "            ReLU-337           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-338           [-1, 64, 14, 14]               0\n",
            "          Conv2d-339           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-340           [-1, 64, 14, 14]             128\n",
            "            ReLU-341           [-1, 64, 14, 14]               0\n",
            "        dw_block-342           [-1, 64, 14, 14]               0\n",
            "          Conv2d-343           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-344           [-1, 16, 14, 14]              32\n",
            "            ReLU-345           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-346           [-1, 16, 14, 14]               0\n",
            "          Conv2d-347           [-1, 64, 14, 14]           5,120\n",
            "     BatchNorm2d-348           [-1, 64, 14, 14]             128\n",
            "            ReLU-349           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-350           [-1, 64, 14, 14]               0\n",
            "          Conv2d-351           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-352           [-1, 64, 14, 14]             128\n",
            "            ReLU-353           [-1, 64, 14, 14]               0\n",
            "        dw_block-354           [-1, 64, 14, 14]               0\n",
            "          Conv2d-355           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-356           [-1, 16, 14, 14]              32\n",
            "            ReLU-357           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-358           [-1, 16, 14, 14]               0\n",
            "          Conv2d-359           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-360           [-1, 16, 14, 14]              32\n",
            "            ReLU-361           [-1, 16, 14, 14]               0\n",
            "        dw_block-362           [-1, 16, 14, 14]               0\n",
            "          Conv2d-363           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-364           [-1, 16, 14, 14]              32\n",
            "            ReLU-365           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-366           [-1, 16, 14, 14]               0\n",
            "     dense_layer-367          [-1, 352, 14, 14]               0\n",
            "          Conv2d-368           [-1, 64, 14, 14]           5,632\n",
            "     BatchNorm2d-369           [-1, 64, 14, 14]             128\n",
            "            ReLU-370           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-371           [-1, 64, 14, 14]               0\n",
            "          Conv2d-372           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-373           [-1, 64, 14, 14]             128\n",
            "            ReLU-374           [-1, 64, 14, 14]               0\n",
            "        dw_block-375           [-1, 64, 14, 14]               0\n",
            "          Conv2d-376           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-377           [-1, 16, 14, 14]              32\n",
            "            ReLU-378           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-379           [-1, 16, 14, 14]               0\n",
            "          Conv2d-380           [-1, 64, 14, 14]           5,632\n",
            "     BatchNorm2d-381           [-1, 64, 14, 14]             128\n",
            "            ReLU-382           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-383           [-1, 64, 14, 14]               0\n",
            "          Conv2d-384           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-385           [-1, 64, 14, 14]             128\n",
            "            ReLU-386           [-1, 64, 14, 14]               0\n",
            "        dw_block-387           [-1, 64, 14, 14]               0\n",
            "          Conv2d-388           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-389           [-1, 16, 14, 14]              32\n",
            "            ReLU-390           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-391           [-1, 16, 14, 14]               0\n",
            "          Conv2d-392           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-393           [-1, 16, 14, 14]              32\n",
            "            ReLU-394           [-1, 16, 14, 14]               0\n",
            "        dw_block-395           [-1, 16, 14, 14]               0\n",
            "          Conv2d-396           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-397           [-1, 16, 14, 14]              32\n",
            "            ReLU-398           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-399           [-1, 16, 14, 14]               0\n",
            "     dense_layer-400          [-1, 384, 14, 14]               0\n",
            "          Conv2d-401           [-1, 64, 14, 14]           6,144\n",
            "     BatchNorm2d-402           [-1, 64, 14, 14]             128\n",
            "            ReLU-403           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-404           [-1, 64, 14, 14]               0\n",
            "          Conv2d-405           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-406           [-1, 64, 14, 14]             128\n",
            "            ReLU-407           [-1, 64, 14, 14]               0\n",
            "        dw_block-408           [-1, 64, 14, 14]               0\n",
            "          Conv2d-409           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-410           [-1, 16, 14, 14]              32\n",
            "            ReLU-411           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-412           [-1, 16, 14, 14]               0\n",
            "          Conv2d-413           [-1, 64, 14, 14]           6,144\n",
            "     BatchNorm2d-414           [-1, 64, 14, 14]             128\n",
            "            ReLU-415           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-416           [-1, 64, 14, 14]               0\n",
            "          Conv2d-417           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-418           [-1, 64, 14, 14]             128\n",
            "            ReLU-419           [-1, 64, 14, 14]               0\n",
            "        dw_block-420           [-1, 64, 14, 14]               0\n",
            "          Conv2d-421           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-422           [-1, 16, 14, 14]              32\n",
            "            ReLU-423           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-424           [-1, 16, 14, 14]               0\n",
            "          Conv2d-425           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-426           [-1, 16, 14, 14]              32\n",
            "            ReLU-427           [-1, 16, 14, 14]               0\n",
            "        dw_block-428           [-1, 16, 14, 14]               0\n",
            "          Conv2d-429           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-430           [-1, 16, 14, 14]              32\n",
            "            ReLU-431           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-432           [-1, 16, 14, 14]               0\n",
            "     dense_layer-433          [-1, 416, 14, 14]               0\n",
            "          Conv2d-434           [-1, 64, 14, 14]           6,656\n",
            "     BatchNorm2d-435           [-1, 64, 14, 14]             128\n",
            "            ReLU-436           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-437           [-1, 64, 14, 14]               0\n",
            "          Conv2d-438           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-439           [-1, 64, 14, 14]             128\n",
            "            ReLU-440           [-1, 64, 14, 14]               0\n",
            "        dw_block-441           [-1, 64, 14, 14]               0\n",
            "          Conv2d-442           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-443           [-1, 16, 14, 14]              32\n",
            "            ReLU-444           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-445           [-1, 16, 14, 14]               0\n",
            "          Conv2d-446           [-1, 64, 14, 14]           6,656\n",
            "     BatchNorm2d-447           [-1, 64, 14, 14]             128\n",
            "            ReLU-448           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-449           [-1, 64, 14, 14]               0\n",
            "          Conv2d-450           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-451           [-1, 64, 14, 14]             128\n",
            "            ReLU-452           [-1, 64, 14, 14]               0\n",
            "        dw_block-453           [-1, 64, 14, 14]               0\n",
            "          Conv2d-454           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-455           [-1, 16, 14, 14]              32\n",
            "            ReLU-456           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-457           [-1, 16, 14, 14]               0\n",
            "          Conv2d-458           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-459           [-1, 16, 14, 14]              32\n",
            "            ReLU-460           [-1, 16, 14, 14]               0\n",
            "        dw_block-461           [-1, 16, 14, 14]               0\n",
            "          Conv2d-462           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-463           [-1, 16, 14, 14]              32\n",
            "            ReLU-464           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-465           [-1, 16, 14, 14]               0\n",
            "     dense_layer-466          [-1, 448, 14, 14]               0\n",
            "          Conv2d-467           [-1, 64, 14, 14]           7,168\n",
            "     BatchNorm2d-468           [-1, 64, 14, 14]             128\n",
            "            ReLU-469           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-470           [-1, 64, 14, 14]               0\n",
            "          Conv2d-471           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-472           [-1, 64, 14, 14]             128\n",
            "            ReLU-473           [-1, 64, 14, 14]               0\n",
            "        dw_block-474           [-1, 64, 14, 14]               0\n",
            "          Conv2d-475           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-476           [-1, 16, 14, 14]              32\n",
            "            ReLU-477           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-478           [-1, 16, 14, 14]               0\n",
            "          Conv2d-479           [-1, 64, 14, 14]           7,168\n",
            "     BatchNorm2d-480           [-1, 64, 14, 14]             128\n",
            "            ReLU-481           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-482           [-1, 64, 14, 14]               0\n",
            "          Conv2d-483           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-484           [-1, 64, 14, 14]             128\n",
            "            ReLU-485           [-1, 64, 14, 14]               0\n",
            "        dw_block-486           [-1, 64, 14, 14]               0\n",
            "          Conv2d-487           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-488           [-1, 16, 14, 14]              32\n",
            "            ReLU-489           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-490           [-1, 16, 14, 14]               0\n",
            "          Conv2d-491           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-492           [-1, 16, 14, 14]              32\n",
            "            ReLU-493           [-1, 16, 14, 14]               0\n",
            "        dw_block-494           [-1, 16, 14, 14]               0\n",
            "          Conv2d-495           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-496           [-1, 16, 14, 14]              32\n",
            "            ReLU-497           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-498           [-1, 16, 14, 14]               0\n",
            "     dense_layer-499          [-1, 480, 14, 14]               0\n",
            "          Conv2d-500           [-1, 64, 14, 14]           7,680\n",
            "     BatchNorm2d-501           [-1, 64, 14, 14]             128\n",
            "            ReLU-502           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-503           [-1, 64, 14, 14]               0\n",
            "          Conv2d-504           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-505           [-1, 64, 14, 14]             128\n",
            "            ReLU-506           [-1, 64, 14, 14]               0\n",
            "        dw_block-507           [-1, 64, 14, 14]               0\n",
            "          Conv2d-508           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-509           [-1, 16, 14, 14]              32\n",
            "            ReLU-510           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-511           [-1, 16, 14, 14]               0\n",
            "          Conv2d-512           [-1, 64, 14, 14]           7,680\n",
            "     BatchNorm2d-513           [-1, 64, 14, 14]             128\n",
            "            ReLU-514           [-1, 64, 14, 14]               0\n",
            "    conv_bn_relu-515           [-1, 64, 14, 14]               0\n",
            "          Conv2d-516           [-1, 64, 14, 14]             576\n",
            "     BatchNorm2d-517           [-1, 64, 14, 14]             128\n",
            "            ReLU-518           [-1, 64, 14, 14]               0\n",
            "        dw_block-519           [-1, 64, 14, 14]               0\n",
            "          Conv2d-520           [-1, 16, 14, 14]             256\n",
            "     BatchNorm2d-521           [-1, 16, 14, 14]              32\n",
            "            ReLU-522           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-523           [-1, 16, 14, 14]               0\n",
            "          Conv2d-524           [-1, 16, 14, 14]             144\n",
            "     BatchNorm2d-525           [-1, 16, 14, 14]              32\n",
            "            ReLU-526           [-1, 16, 14, 14]               0\n",
            "        dw_block-527           [-1, 16, 14, 14]               0\n",
            "          Conv2d-528           [-1, 16, 14, 14]              64\n",
            "     BatchNorm2d-529           [-1, 16, 14, 14]              32\n",
            "            ReLU-530           [-1, 16, 14, 14]               0\n",
            "    conv_bn_relu-531           [-1, 16, 14, 14]               0\n",
            "     dense_layer-532          [-1, 512, 14, 14]               0\n",
            "          Conv2d-533          [-1, 512, 14, 14]         262,144\n",
            "     BatchNorm2d-534          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-535          [-1, 512, 14, 14]               0\n",
            "    conv_bn_relu-536          [-1, 512, 14, 14]               0\n",
            "       AvgPool2d-537            [-1, 512, 7, 7]               0\n",
            "          Conv2d-538             [-1, 64, 7, 7]           8,192\n",
            "     BatchNorm2d-539             [-1, 64, 7, 7]             128\n",
            "            ReLU-540             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-541             [-1, 64, 7, 7]               0\n",
            "          Conv2d-542             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-543             [-1, 64, 7, 7]             128\n",
            "            ReLU-544             [-1, 64, 7, 7]               0\n",
            "        dw_block-545             [-1, 64, 7, 7]               0\n",
            "          Conv2d-546             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-547             [-1, 16, 7, 7]              32\n",
            "            ReLU-548             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-549             [-1, 16, 7, 7]               0\n",
            "          Conv2d-550             [-1, 64, 7, 7]           8,192\n",
            "     BatchNorm2d-551             [-1, 64, 7, 7]             128\n",
            "            ReLU-552             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-553             [-1, 64, 7, 7]               0\n",
            "          Conv2d-554             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-555             [-1, 64, 7, 7]             128\n",
            "            ReLU-556             [-1, 64, 7, 7]               0\n",
            "        dw_block-557             [-1, 64, 7, 7]               0\n",
            "          Conv2d-558             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-559             [-1, 16, 7, 7]              32\n",
            "            ReLU-560             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-561             [-1, 16, 7, 7]               0\n",
            "          Conv2d-562             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-563             [-1, 16, 7, 7]              32\n",
            "            ReLU-564             [-1, 16, 7, 7]               0\n",
            "        dw_block-565             [-1, 16, 7, 7]               0\n",
            "          Conv2d-566             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-567             [-1, 16, 7, 7]              32\n",
            "            ReLU-568             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-569             [-1, 16, 7, 7]               0\n",
            "     dense_layer-570            [-1, 544, 7, 7]               0\n",
            "          Conv2d-571             [-1, 64, 7, 7]           8,704\n",
            "     BatchNorm2d-572             [-1, 64, 7, 7]             128\n",
            "            ReLU-573             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-574             [-1, 64, 7, 7]               0\n",
            "          Conv2d-575             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-576             [-1, 64, 7, 7]             128\n",
            "            ReLU-577             [-1, 64, 7, 7]               0\n",
            "        dw_block-578             [-1, 64, 7, 7]               0\n",
            "          Conv2d-579             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-580             [-1, 16, 7, 7]              32\n",
            "            ReLU-581             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-582             [-1, 16, 7, 7]               0\n",
            "          Conv2d-583             [-1, 64, 7, 7]           8,704\n",
            "     BatchNorm2d-584             [-1, 64, 7, 7]             128\n",
            "            ReLU-585             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-586             [-1, 64, 7, 7]               0\n",
            "          Conv2d-587             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-588             [-1, 64, 7, 7]             128\n",
            "            ReLU-589             [-1, 64, 7, 7]               0\n",
            "        dw_block-590             [-1, 64, 7, 7]               0\n",
            "          Conv2d-591             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-592             [-1, 16, 7, 7]              32\n",
            "            ReLU-593             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-594             [-1, 16, 7, 7]               0\n",
            "          Conv2d-595             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-596             [-1, 16, 7, 7]              32\n",
            "            ReLU-597             [-1, 16, 7, 7]               0\n",
            "        dw_block-598             [-1, 16, 7, 7]               0\n",
            "          Conv2d-599             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-600             [-1, 16, 7, 7]              32\n",
            "            ReLU-601             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-602             [-1, 16, 7, 7]               0\n",
            "     dense_layer-603            [-1, 576, 7, 7]               0\n",
            "          Conv2d-604             [-1, 64, 7, 7]           9,216\n",
            "     BatchNorm2d-605             [-1, 64, 7, 7]             128\n",
            "            ReLU-606             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-607             [-1, 64, 7, 7]               0\n",
            "          Conv2d-608             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-609             [-1, 64, 7, 7]             128\n",
            "            ReLU-610             [-1, 64, 7, 7]               0\n",
            "        dw_block-611             [-1, 64, 7, 7]               0\n",
            "          Conv2d-612             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-613             [-1, 16, 7, 7]              32\n",
            "            ReLU-614             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-615             [-1, 16, 7, 7]               0\n",
            "          Conv2d-616             [-1, 64, 7, 7]           9,216\n",
            "     BatchNorm2d-617             [-1, 64, 7, 7]             128\n",
            "            ReLU-618             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-619             [-1, 64, 7, 7]               0\n",
            "          Conv2d-620             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-621             [-1, 64, 7, 7]             128\n",
            "            ReLU-622             [-1, 64, 7, 7]               0\n",
            "        dw_block-623             [-1, 64, 7, 7]               0\n",
            "          Conv2d-624             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-625             [-1, 16, 7, 7]              32\n",
            "            ReLU-626             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-627             [-1, 16, 7, 7]               0\n",
            "          Conv2d-628             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-629             [-1, 16, 7, 7]              32\n",
            "            ReLU-630             [-1, 16, 7, 7]               0\n",
            "        dw_block-631             [-1, 16, 7, 7]               0\n",
            "          Conv2d-632             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-633             [-1, 16, 7, 7]              32\n",
            "            ReLU-634             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-635             [-1, 16, 7, 7]               0\n",
            "     dense_layer-636            [-1, 608, 7, 7]               0\n",
            "          Conv2d-637             [-1, 64, 7, 7]           9,728\n",
            "     BatchNorm2d-638             [-1, 64, 7, 7]             128\n",
            "            ReLU-639             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-640             [-1, 64, 7, 7]               0\n",
            "          Conv2d-641             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-642             [-1, 64, 7, 7]             128\n",
            "            ReLU-643             [-1, 64, 7, 7]               0\n",
            "        dw_block-644             [-1, 64, 7, 7]               0\n",
            "          Conv2d-645             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-646             [-1, 16, 7, 7]              32\n",
            "            ReLU-647             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-648             [-1, 16, 7, 7]               0\n",
            "          Conv2d-649             [-1, 64, 7, 7]           9,728\n",
            "     BatchNorm2d-650             [-1, 64, 7, 7]             128\n",
            "            ReLU-651             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-652             [-1, 64, 7, 7]               0\n",
            "          Conv2d-653             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-654             [-1, 64, 7, 7]             128\n",
            "            ReLU-655             [-1, 64, 7, 7]               0\n",
            "        dw_block-656             [-1, 64, 7, 7]               0\n",
            "          Conv2d-657             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-658             [-1, 16, 7, 7]              32\n",
            "            ReLU-659             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-660             [-1, 16, 7, 7]               0\n",
            "          Conv2d-661             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-662             [-1, 16, 7, 7]              32\n",
            "            ReLU-663             [-1, 16, 7, 7]               0\n",
            "        dw_block-664             [-1, 16, 7, 7]               0\n",
            "          Conv2d-665             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-666             [-1, 16, 7, 7]              32\n",
            "            ReLU-667             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-668             [-1, 16, 7, 7]               0\n",
            "     dense_layer-669            [-1, 640, 7, 7]               0\n",
            "          Conv2d-670             [-1, 64, 7, 7]          10,240\n",
            "     BatchNorm2d-671             [-1, 64, 7, 7]             128\n",
            "            ReLU-672             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-673             [-1, 64, 7, 7]               0\n",
            "          Conv2d-674             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-675             [-1, 64, 7, 7]             128\n",
            "            ReLU-676             [-1, 64, 7, 7]               0\n",
            "        dw_block-677             [-1, 64, 7, 7]               0\n",
            "          Conv2d-678             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-679             [-1, 16, 7, 7]              32\n",
            "            ReLU-680             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-681             [-1, 16, 7, 7]               0\n",
            "          Conv2d-682             [-1, 64, 7, 7]          10,240\n",
            "     BatchNorm2d-683             [-1, 64, 7, 7]             128\n",
            "            ReLU-684             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-685             [-1, 64, 7, 7]               0\n",
            "          Conv2d-686             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-687             [-1, 64, 7, 7]             128\n",
            "            ReLU-688             [-1, 64, 7, 7]               0\n",
            "        dw_block-689             [-1, 64, 7, 7]               0\n",
            "          Conv2d-690             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-691             [-1, 16, 7, 7]              32\n",
            "            ReLU-692             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-693             [-1, 16, 7, 7]               0\n",
            "          Conv2d-694             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-695             [-1, 16, 7, 7]              32\n",
            "            ReLU-696             [-1, 16, 7, 7]               0\n",
            "        dw_block-697             [-1, 16, 7, 7]               0\n",
            "          Conv2d-698             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-699             [-1, 16, 7, 7]              32\n",
            "            ReLU-700             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-701             [-1, 16, 7, 7]               0\n",
            "     dense_layer-702            [-1, 672, 7, 7]               0\n",
            "          Conv2d-703             [-1, 64, 7, 7]          10,752\n",
            "     BatchNorm2d-704             [-1, 64, 7, 7]             128\n",
            "            ReLU-705             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-706             [-1, 64, 7, 7]               0\n",
            "          Conv2d-707             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-708             [-1, 64, 7, 7]             128\n",
            "            ReLU-709             [-1, 64, 7, 7]               0\n",
            "        dw_block-710             [-1, 64, 7, 7]               0\n",
            "          Conv2d-711             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-712             [-1, 16, 7, 7]              32\n",
            "            ReLU-713             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-714             [-1, 16, 7, 7]               0\n",
            "          Conv2d-715             [-1, 64, 7, 7]          10,752\n",
            "     BatchNorm2d-716             [-1, 64, 7, 7]             128\n",
            "            ReLU-717             [-1, 64, 7, 7]               0\n",
            "    conv_bn_relu-718             [-1, 64, 7, 7]               0\n",
            "          Conv2d-719             [-1, 64, 7, 7]             576\n",
            "     BatchNorm2d-720             [-1, 64, 7, 7]             128\n",
            "            ReLU-721             [-1, 64, 7, 7]               0\n",
            "        dw_block-722             [-1, 64, 7, 7]               0\n",
            "          Conv2d-723             [-1, 16, 7, 7]             256\n",
            "     BatchNorm2d-724             [-1, 16, 7, 7]              32\n",
            "            ReLU-725             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-726             [-1, 16, 7, 7]               0\n",
            "          Conv2d-727             [-1, 16, 7, 7]             144\n",
            "     BatchNorm2d-728             [-1, 16, 7, 7]              32\n",
            "            ReLU-729             [-1, 16, 7, 7]               0\n",
            "        dw_block-730             [-1, 16, 7, 7]               0\n",
            "          Conv2d-731             [-1, 16, 7, 7]              64\n",
            "     BatchNorm2d-732             [-1, 16, 7, 7]              32\n",
            "            ReLU-733             [-1, 16, 7, 7]               0\n",
            "    conv_bn_relu-734             [-1, 16, 7, 7]               0\n",
            "     dense_layer-735            [-1, 704, 7, 7]               0\n",
            "          Conv2d-736            [-1, 704, 7, 7]         495,616\n",
            "     BatchNorm2d-737            [-1, 704, 7, 7]           1,408\n",
            "            ReLU-738            [-1, 704, 7, 7]               0\n",
            "    conv_bn_relu-739            [-1, 704, 7, 7]               0\n",
            "          Conv2d-740             [-1, 10, 1, 1]           3,530\n",
            "================================================================\n",
            "Total params: 1,137,003\n",
            "Trainable params: 1,137,003\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 212.81\n",
            "Params size (MB): 4.34\n",
            "Estimated Total Size (MB): 217.72\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHIpFyXxCbd4",
        "colab_type": "code",
        "outputId": "12f33c73-b250-42e6-afac-b2e63bdc0d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=initial_lr, momentum=0.9)\n",
        "learning_rate_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epoch)\n",
        "\n",
        "for epoch in range(num_epoch):  \n",
        "    learning_rate_scheduler.step()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "                \n",
        "        show_period = 100\n",
        "        if i % show_period ==  show_period-1:    # print every \"show_period\" mini-batches\n",
        "            print('[%d, %5d/50000] loss: %.7f, lr: %.7f' %\n",
        "                  (epoch + 1, (i + 1)*batch_size, running_loss / show_period, learning_rate_scheduler.get_lr()[0]))\n",
        "            running_loss = 0.0\n",
        "            \n",
        "    # validation part\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(valid_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
        "          (epoch + 1, 100 * correct / total)\n",
        "         )\n",
        "\n",
        "print('Finished Training')\n",
        "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:484: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,  6400/50000] loss: 1.9977075, lr: 0.0999507\n",
            "[1, 12800/50000] loss: 1.6388316, lr: 0.0999507\n",
            "[1, 19200/50000] loss: 1.5072587, lr: 0.0999507\n",
            "[1, 25600/50000] loss: 1.3588868, lr: 0.0999507\n",
            "[1, 32000/50000] loss: 1.2588971, lr: 0.0999507\n",
            "[1, 38400/50000] loss: 1.1788518, lr: 0.0999507\n",
            "[1, 44800/50000] loss: 1.1464753, lr: 0.0999507\n",
            "[1 epoch] Accuracy of the network on the validation images: 61 %\n",
            "[2,  6400/50000] loss: 1.0592103, lr: 0.0998274\n",
            "[2, 12800/50000] loss: 1.0228580, lr: 0.0998274\n",
            "[2, 19200/50000] loss: 0.9897326, lr: 0.0998274\n",
            "[2, 25600/50000] loss: 0.9309348, lr: 0.0998274\n",
            "[2, 32000/50000] loss: 0.9024172, lr: 0.0998274\n",
            "[2, 38400/50000] loss: 0.8296773, lr: 0.0998274\n",
            "[2, 44800/50000] loss: 0.8393743, lr: 0.0998274\n",
            "[2 epoch] Accuracy of the network on the validation images: 68 %\n",
            "[3,  6400/50000] loss: 0.8381393, lr: 0.0996550\n",
            "[3, 12800/50000] loss: 0.7861595, lr: 0.0996550\n",
            "[3, 19200/50000] loss: 0.7256991, lr: 0.0996550\n",
            "[3, 25600/50000] loss: 0.6995967, lr: 0.0996550\n",
            "[3, 32000/50000] loss: 0.6844198, lr: 0.0996550\n",
            "[3, 38400/50000] loss: 0.7033280, lr: 0.0996550\n",
            "[3, 44800/50000] loss: 0.6800611, lr: 0.0996550\n",
            "[3 epoch] Accuracy of the network on the validation images: 77 %\n",
            "[4,  6400/50000] loss: 0.6357175, lr: 0.0994337\n",
            "[4, 12800/50000] loss: 0.6135783, lr: 0.0994337\n",
            "[4, 19200/50000] loss: 0.6363861, lr: 0.0994337\n",
            "[4, 25600/50000] loss: 0.5881458, lr: 0.0994337\n",
            "[4, 32000/50000] loss: 0.6072404, lr: 0.0994337\n",
            "[4, 38400/50000] loss: 0.5894195, lr: 0.0994337\n",
            "[4, 44800/50000] loss: 0.5844527, lr: 0.0994337\n",
            "[4 epoch] Accuracy of the network on the validation images: 79 %\n",
            "[5,  6400/50000] loss: 0.5305771, lr: 0.0991636\n",
            "[5, 12800/50000] loss: 0.5433125, lr: 0.0991636\n",
            "[5, 19200/50000] loss: 0.5388895, lr: 0.0991636\n",
            "[5, 25600/50000] loss: 0.5296513, lr: 0.0991636\n",
            "[5, 32000/50000] loss: 0.5207526, lr: 0.0991636\n",
            "[5, 38400/50000] loss: 0.5223188, lr: 0.0991636\n",
            "[5, 44800/50000] loss: 0.5308159, lr: 0.0991636\n",
            "[5 epoch] Accuracy of the network on the validation images: 81 %\n",
            "[6,  6400/50000] loss: 0.4903070, lr: 0.0988450\n",
            "[6, 12800/50000] loss: 0.4772945, lr: 0.0988450\n",
            "[6, 19200/50000] loss: 0.4715092, lr: 0.0988450\n",
            "[6, 25600/50000] loss: 0.4515539, lr: 0.0988450\n",
            "[6, 32000/50000] loss: 0.4661443, lr: 0.0988450\n",
            "[6, 38400/50000] loss: 0.4784011, lr: 0.0988450\n",
            "[6, 44800/50000] loss: 0.4698295, lr: 0.0988450\n",
            "[6 epoch] Accuracy of the network on the validation images: 83 %\n",
            "[7,  6400/50000] loss: 0.4548220, lr: 0.0984783\n",
            "[7, 12800/50000] loss: 0.4254428, lr: 0.0984783\n",
            "[7, 19200/50000] loss: 0.4357473, lr: 0.0984783\n",
            "[7, 25600/50000] loss: 0.4338313, lr: 0.0984783\n",
            "[7, 32000/50000] loss: 0.4293539, lr: 0.0984783\n",
            "[7, 38400/50000] loss: 0.4183914, lr: 0.0984783\n",
            "[7, 44800/50000] loss: 0.4380388, lr: 0.0984783\n",
            "[7 epoch] Accuracy of the network on the validation images: 84 %\n",
            "[8,  6400/50000] loss: 0.3868841, lr: 0.0980638\n",
            "[8, 12800/50000] loss: 0.4128779, lr: 0.0980638\n",
            "[8, 19200/50000] loss: 0.3892973, lr: 0.0980638\n",
            "[8, 25600/50000] loss: 0.4000692, lr: 0.0980638\n",
            "[8, 32000/50000] loss: 0.4040950, lr: 0.0980638\n",
            "[8, 38400/50000] loss: 0.3756597, lr: 0.0980638\n",
            "[8, 44800/50000] loss: 0.4092120, lr: 0.0980638\n",
            "[8 epoch] Accuracy of the network on the validation images: 83 %\n",
            "[9,  6400/50000] loss: 0.3852755, lr: 0.0976020\n",
            "[9, 12800/50000] loss: 0.3675347, lr: 0.0976020\n",
            "[9, 19200/50000] loss: 0.3760895, lr: 0.0976020\n",
            "[9, 25600/50000] loss: 0.3591968, lr: 0.0976020\n",
            "[9, 32000/50000] loss: 0.3642286, lr: 0.0976020\n",
            "[9, 38400/50000] loss: 0.3771830, lr: 0.0976020\n",
            "[9, 44800/50000] loss: 0.3599753, lr: 0.0976020\n",
            "[9 epoch] Accuracy of the network on the validation images: 85 %\n",
            "[10,  6400/50000] loss: 0.3497450, lr: 0.0970931\n",
            "[10, 12800/50000] loss: 0.3195045, lr: 0.0970931\n",
            "[10, 19200/50000] loss: 0.3370147, lr: 0.0970931\n",
            "[10, 25600/50000] loss: 0.3245199, lr: 0.0970931\n",
            "[10, 32000/50000] loss: 0.3624205, lr: 0.0970931\n",
            "[10, 38400/50000] loss: 0.3425276, lr: 0.0970931\n",
            "[10, 44800/50000] loss: 0.3515108, lr: 0.0970931\n",
            "[10 epoch] Accuracy of the network on the validation images: 86 %\n",
            "[11,  6400/50000] loss: 0.3026314, lr: 0.0965379\n",
            "[11, 12800/50000] loss: 0.3145579, lr: 0.0965379\n",
            "[11, 19200/50000] loss: 0.3155634, lr: 0.0965379\n",
            "[11, 25600/50000] loss: 0.3561225, lr: 0.0965379\n",
            "[11, 32000/50000] loss: 0.3157939, lr: 0.0965379\n",
            "[11, 38400/50000] loss: 0.3168011, lr: 0.0965379\n",
            "[11, 44800/50000] loss: 0.3265307, lr: 0.0965379\n",
            "[11 epoch] Accuracy of the network on the validation images: 86 %\n",
            "[12,  6400/50000] loss: 0.2847068, lr: 0.0959368\n",
            "[12, 12800/50000] loss: 0.3051645, lr: 0.0959368\n",
            "[12, 19200/50000] loss: 0.2966235, lr: 0.0959368\n",
            "[12, 25600/50000] loss: 0.3097742, lr: 0.0959368\n",
            "[12, 32000/50000] loss: 0.2957881, lr: 0.0959368\n",
            "[12, 38400/50000] loss: 0.2914007, lr: 0.0959368\n",
            "[12, 44800/50000] loss: 0.3007035, lr: 0.0959368\n",
            "[12 epoch] Accuracy of the network on the validation images: 86 %\n",
            "[13,  6400/50000] loss: 0.2806002, lr: 0.0952904\n",
            "[13, 12800/50000] loss: 0.2687761, lr: 0.0952904\n",
            "[13, 19200/50000] loss: 0.2741686, lr: 0.0952904\n",
            "[13, 25600/50000] loss: 0.3006625, lr: 0.0952904\n",
            "[13, 32000/50000] loss: 0.2747822, lr: 0.0952904\n",
            "[13, 38400/50000] loss: 0.2925264, lr: 0.0952904\n",
            "[13, 44800/50000] loss: 0.2798514, lr: 0.0952904\n",
            "[13 epoch] Accuracy of the network on the validation images: 86 %\n",
            "[14,  6400/50000] loss: 0.2489034, lr: 0.0945993\n",
            "[14, 12800/50000] loss: 0.2540997, lr: 0.0945993\n",
            "[14, 19200/50000] loss: 0.2777515, lr: 0.0945993\n",
            "[14, 25600/50000] loss: 0.2572835, lr: 0.0945993\n",
            "[14, 32000/50000] loss: 0.2736150, lr: 0.0945993\n",
            "[14, 38400/50000] loss: 0.2684789, lr: 0.0945993\n",
            "[14, 44800/50000] loss: 0.2787201, lr: 0.0945993\n",
            "[14 epoch] Accuracy of the network on the validation images: 86 %\n",
            "[15,  6400/50000] loss: 0.2418235, lr: 0.0938643\n",
            "[15, 12800/50000] loss: 0.2226356, lr: 0.0938643\n",
            "[15, 19200/50000] loss: 0.2473313, lr: 0.0938643\n",
            "[15, 25600/50000] loss: 0.2514453, lr: 0.0938643\n",
            "[15, 32000/50000] loss: 0.2585861, lr: 0.0938643\n",
            "[15, 38400/50000] loss: 0.2553333, lr: 0.0938643\n",
            "[15, 44800/50000] loss: 0.2540707, lr: 0.0938643\n",
            "[15 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[16,  6400/50000] loss: 0.2158571, lr: 0.0930861\n",
            "[16, 12800/50000] loss: 0.2188095, lr: 0.0930861\n",
            "[16, 19200/50000] loss: 0.2276625, lr: 0.0930861\n",
            "[16, 25600/50000] loss: 0.2392815, lr: 0.0930861\n",
            "[16, 32000/50000] loss: 0.2358869, lr: 0.0930861\n",
            "[16, 38400/50000] loss: 0.2447678, lr: 0.0930861\n",
            "[16, 44800/50000] loss: 0.2585075, lr: 0.0930861\n",
            "[16 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[17,  6400/50000] loss: 0.2242298, lr: 0.0922653\n",
            "[17, 12800/50000] loss: 0.2179683, lr: 0.0922653\n",
            "[17, 19200/50000] loss: 0.2103374, lr: 0.0922653\n",
            "[17, 25600/50000] loss: 0.2196038, lr: 0.0922653\n",
            "[17, 32000/50000] loss: 0.2144421, lr: 0.0922653\n",
            "[17, 38400/50000] loss: 0.2174608, lr: 0.0922653\n",
            "[17, 44800/50000] loss: 0.2336322, lr: 0.0922653\n",
            "[17 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[18,  6400/50000] loss: 0.2066463, lr: 0.0914029\n",
            "[18, 12800/50000] loss: 0.1965926, lr: 0.0914029\n",
            "[18, 19200/50000] loss: 0.2097725, lr: 0.0914029\n",
            "[18, 25600/50000] loss: 0.2021013, lr: 0.0914029\n",
            "[18, 32000/50000] loss: 0.2148056, lr: 0.0914029\n",
            "[18, 38400/50000] loss: 0.2148792, lr: 0.0914029\n",
            "[18, 44800/50000] loss: 0.2205790, lr: 0.0914029\n",
            "[18 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[19,  6400/50000] loss: 0.2175146, lr: 0.0904997\n",
            "[19, 12800/50000] loss: 0.1994128, lr: 0.0904997\n",
            "[19, 19200/50000] loss: 0.1852653, lr: 0.0904997\n",
            "[19, 25600/50000] loss: 0.1976909, lr: 0.0904997\n",
            "[19, 32000/50000] loss: 0.1992806, lr: 0.0904997\n",
            "[19, 38400/50000] loss: 0.1963310, lr: 0.0904997\n",
            "[19, 44800/50000] loss: 0.2076652, lr: 0.0904997\n",
            "[19 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[20,  6400/50000] loss: 0.1790886, lr: 0.0895566\n",
            "[20, 12800/50000] loss: 0.1669785, lr: 0.0895566\n",
            "[20, 19200/50000] loss: 0.1855545, lr: 0.0895566\n",
            "[20, 25600/50000] loss: 0.1821493, lr: 0.0895566\n",
            "[20, 32000/50000] loss: 0.1888342, lr: 0.0895566\n",
            "[20, 38400/50000] loss: 0.1998513, lr: 0.0895566\n",
            "[20, 44800/50000] loss: 0.1921700, lr: 0.0895566\n",
            "[20 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[21,  6400/50000] loss: 0.1688632, lr: 0.0885745\n",
            "[21, 12800/50000] loss: 0.1787911, lr: 0.0885745\n",
            "[21, 19200/50000] loss: 0.1652931, lr: 0.0885745\n",
            "[21, 25600/50000] loss: 0.1715539, lr: 0.0885745\n",
            "[21, 32000/50000] loss: 0.1553452, lr: 0.0885745\n",
            "[21, 38400/50000] loss: 0.1974063, lr: 0.0885745\n",
            "[21, 44800/50000] loss: 0.1839332, lr: 0.0885745\n",
            "[21 epoch] Accuracy of the network on the validation images: 87 %\n",
            "[22,  6400/50000] loss: 0.1613610, lr: 0.0875543\n",
            "[22, 12800/50000] loss: 0.1445494, lr: 0.0875543\n",
            "[22, 19200/50000] loss: 0.1497526, lr: 0.0875543\n",
            "[22, 25600/50000] loss: 0.1739073, lr: 0.0875543\n",
            "[22, 32000/50000] loss: 0.1716338, lr: 0.0875543\n",
            "[22, 38400/50000] loss: 0.1788358, lr: 0.0875543\n",
            "[22, 44800/50000] loss: 0.1695974, lr: 0.0875543\n",
            "[22 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[23,  6400/50000] loss: 0.1517632, lr: 0.0864972\n",
            "[23, 12800/50000] loss: 0.1575275, lr: 0.0864972\n",
            "[23, 19200/50000] loss: 0.1594085, lr: 0.0864972\n",
            "[23, 25600/50000] loss: 0.1455662, lr: 0.0864972\n",
            "[23, 32000/50000] loss: 0.1631557, lr: 0.0864972\n",
            "[23, 38400/50000] loss: 0.1640244, lr: 0.0864972\n",
            "[23, 44800/50000] loss: 0.1597175, lr: 0.0864972\n",
            "[23 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[24,  6400/50000] loss: 0.1489028, lr: 0.0854041\n",
            "[24, 12800/50000] loss: 0.1484576, lr: 0.0854041\n",
            "[24, 19200/50000] loss: 0.1446124, lr: 0.0854041\n",
            "[24, 25600/50000] loss: 0.1472986, lr: 0.0854041\n",
            "[24, 32000/50000] loss: 0.1608924, lr: 0.0854041\n",
            "[24, 38400/50000] loss: 0.1640439, lr: 0.0854041\n",
            "[24, 44800/50000] loss: 0.1468522, lr: 0.0854041\n",
            "[24 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[25,  6400/50000] loss: 0.1747913, lr: 0.0842761\n",
            "[25, 12800/50000] loss: 0.1454217, lr: 0.0842761\n",
            "[25, 19200/50000] loss: 0.1472560, lr: 0.0842761\n",
            "[25, 25600/50000] loss: 0.1462324, lr: 0.0842761\n",
            "[25, 32000/50000] loss: 0.1458022, lr: 0.0842761\n",
            "[25, 38400/50000] loss: 0.1355082, lr: 0.0842761\n",
            "[25, 44800/50000] loss: 0.1571116, lr: 0.0842761\n",
            "[25 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[26,  6400/50000] loss: 0.1217131, lr: 0.0831143\n",
            "[26, 12800/50000] loss: 0.1244367, lr: 0.0831143\n",
            "[26, 19200/50000] loss: 0.1314680, lr: 0.0831143\n",
            "[26, 25600/50000] loss: 0.1301697, lr: 0.0831143\n",
            "[26, 32000/50000] loss: 0.1302173, lr: 0.0831143\n",
            "[26, 38400/50000] loss: 0.1498153, lr: 0.0831143\n",
            "[26, 44800/50000] loss: 0.1451020, lr: 0.0831143\n",
            "[26 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[27,  6400/50000] loss: 0.1400131, lr: 0.0819199\n",
            "[27, 12800/50000] loss: 0.1228641, lr: 0.0819199\n",
            "[27, 19200/50000] loss: 0.1301944, lr: 0.0819199\n",
            "[27, 25600/50000] loss: 0.1277337, lr: 0.0819199\n",
            "[27, 32000/50000] loss: 0.1279243, lr: 0.0819199\n",
            "[27, 38400/50000] loss: 0.1305050, lr: 0.0819199\n",
            "[27, 44800/50000] loss: 0.1283813, lr: 0.0819199\n",
            "[27 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[28,  6400/50000] loss: 0.1026261, lr: 0.0806940\n",
            "[28, 12800/50000] loss: 0.1129925, lr: 0.0806940\n",
            "[28, 19200/50000] loss: 0.1196996, lr: 0.0806940\n",
            "[28, 25600/50000] loss: 0.1091390, lr: 0.0806940\n",
            "[28, 32000/50000] loss: 0.1122949, lr: 0.0806940\n",
            "[28, 38400/50000] loss: 0.1115177, lr: 0.0806940\n",
            "[28, 44800/50000] loss: 0.1282134, lr: 0.0806940\n",
            "[28 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[29,  6400/50000] loss: 0.1065211, lr: 0.0794379\n",
            "[29, 12800/50000] loss: 0.1085604, lr: 0.0794379\n",
            "[29, 19200/50000] loss: 0.1068840, lr: 0.0794379\n",
            "[29, 25600/50000] loss: 0.1172406, lr: 0.0794379\n",
            "[29, 32000/50000] loss: 0.1110723, lr: 0.0794379\n",
            "[29, 38400/50000] loss: 0.1150724, lr: 0.0794379\n",
            "[29, 44800/50000] loss: 0.1169794, lr: 0.0794379\n",
            "[29 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[30,  6400/50000] loss: 0.1409951, lr: 0.0781527\n",
            "[30, 12800/50000] loss: 0.1163938, lr: 0.0781527\n",
            "[30, 19200/50000] loss: 0.1104852, lr: 0.0781527\n",
            "[30, 25600/50000] loss: 0.1000294, lr: 0.0781527\n",
            "[30, 32000/50000] loss: 0.1117779, lr: 0.0781527\n",
            "[30, 38400/50000] loss: 0.1022126, lr: 0.0781527\n",
            "[30, 44800/50000] loss: 0.1072887, lr: 0.0781527\n",
            "[30 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[31,  6400/50000] loss: 0.1119020, lr: 0.0768399\n",
            "[31, 12800/50000] loss: 0.0987263, lr: 0.0768399\n",
            "[31, 19200/50000] loss: 0.1166719, lr: 0.0768399\n",
            "[31, 25600/50000] loss: 0.1084114, lr: 0.0768399\n",
            "[31, 32000/50000] loss: 0.1046123, lr: 0.0768399\n",
            "[31, 38400/50000] loss: 0.1046830, lr: 0.0768399\n",
            "[31, 44800/50000] loss: 0.1066289, lr: 0.0768399\n",
            "[31 epoch] Accuracy of the network on the validation images: 88 %\n",
            "[32,  6400/50000] loss: 0.0948136, lr: 0.0755006\n",
            "[32, 12800/50000] loss: 0.0875362, lr: 0.0755006\n",
            "[32, 19200/50000] loss: 0.0900743, lr: 0.0755006\n",
            "[32, 25600/50000] loss: 0.0922622, lr: 0.0755006\n",
            "[32, 32000/50000] loss: 0.0904538, lr: 0.0755006\n",
            "[32, 38400/50000] loss: 0.0873750, lr: 0.0755006\n",
            "[32, 44800/50000] loss: 0.1124413, lr: 0.0755006\n",
            "[32 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[33,  6400/50000] loss: 0.0754314, lr: 0.0741362\n",
            "[33, 12800/50000] loss: 0.0681604, lr: 0.0741362\n",
            "[33, 19200/50000] loss: 0.0796064, lr: 0.0741362\n",
            "[33, 25600/50000] loss: 0.0835903, lr: 0.0741362\n",
            "[33, 32000/50000] loss: 0.0870554, lr: 0.0741362\n",
            "[33, 38400/50000] loss: 0.0927364, lr: 0.0741362\n",
            "[33, 44800/50000] loss: 0.0861197, lr: 0.0741362\n",
            "[33 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[34,  6400/50000] loss: 0.1001556, lr: 0.0727480\n",
            "[34, 12800/50000] loss: 0.0769536, lr: 0.0727480\n",
            "[34, 19200/50000] loss: 0.0732559, lr: 0.0727480\n",
            "[34, 25600/50000] loss: 0.0920210, lr: 0.0727480\n",
            "[34, 32000/50000] loss: 0.0956915, lr: 0.0727480\n",
            "[34, 38400/50000] loss: 0.0960928, lr: 0.0727480\n",
            "[34, 44800/50000] loss: 0.0718635, lr: 0.0727480\n",
            "[34 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[35,  6400/50000] loss: 0.0763301, lr: 0.0713374\n",
            "[35, 12800/50000] loss: 0.0878393, lr: 0.0713374\n",
            "[35, 19200/50000] loss: 0.0697039, lr: 0.0713374\n",
            "[35, 25600/50000] loss: 0.0777918, lr: 0.0713374\n",
            "[35, 32000/50000] loss: 0.0784297, lr: 0.0713374\n",
            "[35, 38400/50000] loss: 0.0760842, lr: 0.0713374\n",
            "[35, 44800/50000] loss: 0.0881789, lr: 0.0713374\n",
            "[35 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[36,  6400/50000] loss: 0.0674351, lr: 0.0699058\n",
            "[36, 12800/50000] loss: 0.0757366, lr: 0.0699058\n",
            "[36, 19200/50000] loss: 0.0655050, lr: 0.0699058\n",
            "[36, 25600/50000] loss: 0.0793010, lr: 0.0699058\n",
            "[36, 32000/50000] loss: 0.0773001, lr: 0.0699058\n",
            "[36, 38400/50000] loss: 0.0790215, lr: 0.0699058\n",
            "[36, 44800/50000] loss: 0.0718581, lr: 0.0699058\n",
            "[36 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[37,  6400/50000] loss: 0.0779973, lr: 0.0684546\n",
            "[37, 12800/50000] loss: 0.0717710, lr: 0.0684546\n",
            "[37, 19200/50000] loss: 0.0617986, lr: 0.0684546\n",
            "[37, 25600/50000] loss: 0.0714540, lr: 0.0684546\n",
            "[37, 32000/50000] loss: 0.0688036, lr: 0.0684546\n",
            "[37, 38400/50000] loss: 0.0642619, lr: 0.0684546\n",
            "[37, 44800/50000] loss: 0.0736221, lr: 0.0684546\n",
            "[37 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[38,  6400/50000] loss: 0.0600816, lr: 0.0669852\n",
            "[38, 12800/50000] loss: 0.0654717, lr: 0.0669852\n",
            "[38, 19200/50000] loss: 0.0637975, lr: 0.0669852\n",
            "[38, 25600/50000] loss: 0.0731092, lr: 0.0669852\n",
            "[38, 32000/50000] loss: 0.0629913, lr: 0.0669852\n",
            "[38, 38400/50000] loss: 0.0702940, lr: 0.0669852\n",
            "[38, 44800/50000] loss: 0.0515687, lr: 0.0669852\n",
            "[38 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[39,  6400/50000] loss: 0.0583974, lr: 0.0654991\n",
            "[39, 12800/50000] loss: 0.0484787, lr: 0.0654991\n",
            "[39, 19200/50000] loss: 0.0579244, lr: 0.0654991\n",
            "[39, 25600/50000] loss: 0.0689126, lr: 0.0654991\n",
            "[39, 32000/50000] loss: 0.0591536, lr: 0.0654991\n",
            "[39, 38400/50000] loss: 0.0600327, lr: 0.0654991\n",
            "[39, 44800/50000] loss: 0.0726587, lr: 0.0654991\n",
            "[39 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[40,  6400/50000] loss: 0.0476832, lr: 0.0639978\n",
            "[40, 12800/50000] loss: 0.0521311, lr: 0.0639978\n",
            "[40, 19200/50000] loss: 0.0580742, lr: 0.0639978\n",
            "[40, 25600/50000] loss: 0.0625085, lr: 0.0639978\n",
            "[40, 32000/50000] loss: 0.0609891, lr: 0.0639978\n",
            "[40, 38400/50000] loss: 0.0600520, lr: 0.0639978\n",
            "[40, 44800/50000] loss: 0.0625233, lr: 0.0639978\n",
            "[40 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[41,  6400/50000] loss: 0.0507941, lr: 0.0624827\n",
            "[41, 12800/50000] loss: 0.0451024, lr: 0.0624827\n",
            "[41, 19200/50000] loss: 0.0450310, lr: 0.0624827\n",
            "[41, 25600/50000] loss: 0.0551482, lr: 0.0624827\n",
            "[41, 32000/50000] loss: 0.0506016, lr: 0.0624827\n",
            "[41, 38400/50000] loss: 0.0633758, lr: 0.0624827\n",
            "[41, 44800/50000] loss: 0.0636973, lr: 0.0624827\n",
            "[41 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[42,  6400/50000] loss: 0.0473581, lr: 0.0609553\n",
            "[42, 12800/50000] loss: 0.0492485, lr: 0.0609553\n",
            "[42, 19200/50000] loss: 0.0480484, lr: 0.0609553\n",
            "[42, 25600/50000] loss: 0.0494473, lr: 0.0609553\n",
            "[42, 32000/50000] loss: 0.0490867, lr: 0.0609553\n",
            "[42, 38400/50000] loss: 0.0547441, lr: 0.0609553\n",
            "[42, 44800/50000] loss: 0.0623259, lr: 0.0609553\n",
            "[42 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[43,  6400/50000] loss: 0.0970496, lr: 0.0594172\n",
            "[43, 12800/50000] loss: 0.0555718, lr: 0.0594172\n",
            "[43, 19200/50000] loss: 0.0483121, lr: 0.0594172\n",
            "[43, 25600/50000] loss: 0.0469922, lr: 0.0594172\n",
            "[43, 32000/50000] loss: 0.0545636, lr: 0.0594172\n",
            "[43, 38400/50000] loss: 0.0548168, lr: 0.0594172\n",
            "[43, 44800/50000] loss: 0.0547466, lr: 0.0594172\n",
            "[43 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[44,  6400/50000] loss: 0.0581789, lr: 0.0578698\n",
            "[44, 12800/50000] loss: 0.0470609, lr: 0.0578698\n",
            "[44, 19200/50000] loss: 0.0493991, lr: 0.0578698\n",
            "[44, 25600/50000] loss: 0.0493967, lr: 0.0578698\n",
            "[44, 32000/50000] loss: 0.0407299, lr: 0.0578698\n",
            "[44, 38400/50000] loss: 0.0455899, lr: 0.0578698\n",
            "[44, 44800/50000] loss: 0.0451005, lr: 0.0578698\n",
            "[44 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[45,  6400/50000] loss: 0.0514744, lr: 0.0563147\n",
            "[45, 12800/50000] loss: 0.0429521, lr: 0.0563147\n",
            "[45, 19200/50000] loss: 0.0324472, lr: 0.0563147\n",
            "[45, 25600/50000] loss: 0.0430936, lr: 0.0563147\n",
            "[45, 32000/50000] loss: 0.0397799, lr: 0.0563147\n",
            "[45, 38400/50000] loss: 0.0385341, lr: 0.0563147\n",
            "[45, 44800/50000] loss: 0.0425623, lr: 0.0563147\n",
            "[45 epoch] Accuracy of the network on the validation images: 89 %\n",
            "[46,  6400/50000] loss: 0.0395661, lr: 0.0547534\n",
            "[46, 12800/50000] loss: 0.0368511, lr: 0.0547534\n",
            "[46, 19200/50000] loss: 0.0352165, lr: 0.0547534\n",
            "[46, 25600/50000] loss: 0.0406208, lr: 0.0547534\n",
            "[46, 32000/50000] loss: 0.0388057, lr: 0.0547534\n",
            "[46, 38400/50000] loss: 0.0358562, lr: 0.0547534\n",
            "[46, 44800/50000] loss: 0.0383823, lr: 0.0547534\n",
            "[46 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[47,  6400/50000] loss: 0.0305829, lr: 0.0531875\n",
            "[47, 12800/50000] loss: 0.0326018, lr: 0.0531875\n",
            "[47, 19200/50000] loss: 0.0334698, lr: 0.0531875\n",
            "[47, 25600/50000] loss: 0.0356402, lr: 0.0531875\n",
            "[47, 32000/50000] loss: 0.0352007, lr: 0.0531875\n",
            "[47, 38400/50000] loss: 0.0337092, lr: 0.0531875\n",
            "[47, 44800/50000] loss: 0.0362014, lr: 0.0531875\n",
            "[47 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[48,  6400/50000] loss: 0.0267892, lr: 0.0516185\n",
            "[48, 12800/50000] loss: 0.0325903, lr: 0.0516185\n",
            "[48, 19200/50000] loss: 0.0344844, lr: 0.0516185\n",
            "[48, 25600/50000] loss: 0.0343150, lr: 0.0516185\n",
            "[48, 32000/50000] loss: 0.0309234, lr: 0.0516185\n",
            "[48, 38400/50000] loss: 0.0276735, lr: 0.0516185\n",
            "[48, 44800/50000] loss: 0.0350302, lr: 0.0516185\n",
            "[48 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[49,  6400/50000] loss: 0.0389916, lr: 0.0500479\n",
            "[49, 12800/50000] loss: 0.0364277, lr: 0.0500479\n",
            "[49, 19200/50000] loss: 0.0344632, lr: 0.0500479\n",
            "[49, 25600/50000] loss: 0.0307741, lr: 0.0500479\n",
            "[49, 32000/50000] loss: 0.0290285, lr: 0.0500479\n",
            "[49, 38400/50000] loss: 0.0264127, lr: 0.0500479\n",
            "[49, 44800/50000] loss: 0.0328515, lr: 0.0500479\n",
            "[49 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[50,  6400/50000] loss: 0.0411141, lr: 0.0484773\n",
            "[50, 12800/50000] loss: 0.0383208, lr: 0.0484773\n",
            "[50, 19200/50000] loss: 0.0418131, lr: 0.0484773\n",
            "[50, 25600/50000] loss: 0.0354411, lr: 0.0484773\n",
            "[50, 32000/50000] loss: 0.0325095, lr: 0.0484773\n",
            "[50, 38400/50000] loss: 0.0390332, lr: 0.0484773\n",
            "[50, 44800/50000] loss: 0.0329942, lr: 0.0484773\n",
            "[50 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[51,  6400/50000] loss: 0.0276227, lr: 0.0469083\n",
            "[51, 12800/50000] loss: 0.0300341, lr: 0.0469083\n",
            "[51, 19200/50000] loss: 0.0259970, lr: 0.0469083\n",
            "[51, 25600/50000] loss: 0.0281121, lr: 0.0469083\n",
            "[51, 32000/50000] loss: 0.0264389, lr: 0.0469083\n",
            "[51, 38400/50000] loss: 0.0315120, lr: 0.0469083\n",
            "[51, 44800/50000] loss: 0.0295172, lr: 0.0469083\n",
            "[51 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[52,  6400/50000] loss: 0.0210266, lr: 0.0453423\n",
            "[52, 12800/50000] loss: 0.0307545, lr: 0.0453423\n",
            "[52, 19200/50000] loss: 0.0235499, lr: 0.0453423\n",
            "[52, 25600/50000] loss: 0.0223979, lr: 0.0453423\n",
            "[52, 32000/50000] loss: 0.0262136, lr: 0.0453423\n",
            "[52, 38400/50000] loss: 0.0243268, lr: 0.0453423\n",
            "[52, 44800/50000] loss: 0.0227409, lr: 0.0453423\n",
            "[52 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[53,  6400/50000] loss: 0.0255017, lr: 0.0437810\n",
            "[53, 12800/50000] loss: 0.0249735, lr: 0.0437810\n",
            "[53, 19200/50000] loss: 0.0245057, lr: 0.0437810\n",
            "[53, 25600/50000] loss: 0.0202244, lr: 0.0437810\n",
            "[53, 32000/50000] loss: 0.0237892, lr: 0.0437810\n",
            "[53, 38400/50000] loss: 0.0208288, lr: 0.0437810\n",
            "[53, 44800/50000] loss: 0.0230016, lr: 0.0437810\n",
            "[53 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[54,  6400/50000] loss: 0.0347060, lr: 0.0422259\n",
            "[54, 12800/50000] loss: 0.0256638, lr: 0.0422259\n",
            "[54, 19200/50000] loss: 0.0229192, lr: 0.0422259\n",
            "[54, 25600/50000] loss: 0.0222743, lr: 0.0422259\n",
            "[54, 32000/50000] loss: 0.0259042, lr: 0.0422259\n",
            "[54, 38400/50000] loss: 0.0205365, lr: 0.0422259\n",
            "[54, 44800/50000] loss: 0.0223916, lr: 0.0422259\n",
            "[54 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[55,  6400/50000] loss: 0.0193835, lr: 0.0406785\n",
            "[55, 12800/50000] loss: 0.0187936, lr: 0.0406785\n",
            "[55, 19200/50000] loss: 0.0185894, lr: 0.0406785\n",
            "[55, 25600/50000] loss: 0.0182270, lr: 0.0406785\n",
            "[55, 32000/50000] loss: 0.0177699, lr: 0.0406785\n",
            "[55, 38400/50000] loss: 0.0204667, lr: 0.0406785\n",
            "[55, 44800/50000] loss: 0.0177352, lr: 0.0406785\n",
            "[55 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[56,  6400/50000] loss: 0.0203747, lr: 0.0391404\n",
            "[56, 12800/50000] loss: 0.0214599, lr: 0.0391404\n",
            "[56, 19200/50000] loss: 0.0206961, lr: 0.0391404\n",
            "[56, 25600/50000] loss: 0.0144733, lr: 0.0391404\n",
            "[56, 32000/50000] loss: 0.0145635, lr: 0.0391404\n",
            "[56, 38400/50000] loss: 0.0156695, lr: 0.0391404\n",
            "[56, 44800/50000] loss: 0.0220269, lr: 0.0391404\n",
            "[56 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[57,  6400/50000] loss: 0.0282773, lr: 0.0376130\n",
            "[57, 12800/50000] loss: 0.0216070, lr: 0.0376130\n",
            "[57, 19200/50000] loss: 0.0194435, lr: 0.0376130\n",
            "[57, 25600/50000] loss: 0.0191525, lr: 0.0376130\n",
            "[57, 32000/50000] loss: 0.0234813, lr: 0.0376130\n",
            "[57, 38400/50000] loss: 0.0172048, lr: 0.0376130\n",
            "[57, 44800/50000] loss: 0.0161542, lr: 0.0376130\n",
            "[57 epoch] Accuracy of the network on the validation images: 90 %\n",
            "[58,  6400/50000] loss: 0.0152408, lr: 0.0360978\n",
            "[58, 12800/50000] loss: 0.0132405, lr: 0.0360978\n",
            "[58, 19200/50000] loss: 0.0203527, lr: 0.0360978\n",
            "[58, 25600/50000] loss: 0.0153691, lr: 0.0360978\n",
            "[58, 32000/50000] loss: 0.0177934, lr: 0.0360978\n",
            "[58, 38400/50000] loss: 0.0205775, lr: 0.0360978\n",
            "[58, 44800/50000] loss: 0.0124663, lr: 0.0360978\n",
            "[58 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[59,  6400/50000] loss: 0.0192349, lr: 0.0345965\n",
            "[59, 12800/50000] loss: 0.0130258, lr: 0.0345965\n",
            "[59, 19200/50000] loss: 0.0153458, lr: 0.0345965\n",
            "[59, 25600/50000] loss: 0.0128719, lr: 0.0345965\n",
            "[59, 32000/50000] loss: 0.0186433, lr: 0.0345965\n",
            "[59, 38400/50000] loss: 0.0165344, lr: 0.0345965\n",
            "[59, 44800/50000] loss: 0.0172010, lr: 0.0345965\n",
            "[59 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[60,  6400/50000] loss: 0.0093595, lr: 0.0331104\n",
            "[60, 12800/50000] loss: 0.0121753, lr: 0.0331104\n",
            "[60, 19200/50000] loss: 0.0147210, lr: 0.0331104\n",
            "[60, 25600/50000] loss: 0.0166310, lr: 0.0331104\n",
            "[60, 32000/50000] loss: 0.0159013, lr: 0.0331104\n",
            "[60, 38400/50000] loss: 0.0142830, lr: 0.0331104\n",
            "[60, 44800/50000] loss: 0.0122430, lr: 0.0331104\n",
            "[60 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[61,  6400/50000] loss: 0.0214095, lr: 0.0316410\n",
            "[61, 12800/50000] loss: 0.0155111, lr: 0.0316410\n",
            "[61, 19200/50000] loss: 0.0110212, lr: 0.0316410\n",
            "[61, 25600/50000] loss: 0.0128256, lr: 0.0316410\n",
            "[61, 32000/50000] loss: 0.0120018, lr: 0.0316410\n",
            "[61, 38400/50000] loss: 0.0138407, lr: 0.0316410\n",
            "[61, 44800/50000] loss: 0.0153556, lr: 0.0316410\n",
            "[61 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[62,  6400/50000] loss: 0.0151762, lr: 0.0301897\n",
            "[62, 12800/50000] loss: 0.0109769, lr: 0.0301897\n",
            "[62, 19200/50000] loss: 0.0116478, lr: 0.0301897\n",
            "[62, 25600/50000] loss: 0.0107191, lr: 0.0301897\n",
            "[62, 32000/50000] loss: 0.0111351, lr: 0.0301897\n",
            "[62, 38400/50000] loss: 0.0088446, lr: 0.0301897\n",
            "[62, 44800/50000] loss: 0.0125379, lr: 0.0301897\n",
            "[62 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[63,  6400/50000] loss: 0.0122098, lr: 0.0287581\n",
            "[63, 12800/50000] loss: 0.0103427, lr: 0.0287581\n",
            "[63, 19200/50000] loss: 0.0146006, lr: 0.0287581\n",
            "[63, 25600/50000] loss: 0.0120874, lr: 0.0287581\n",
            "[63, 32000/50000] loss: 0.0082704, lr: 0.0287581\n",
            "[63, 38400/50000] loss: 0.0136450, lr: 0.0287581\n",
            "[63, 44800/50000] loss: 0.0138036, lr: 0.0287581\n",
            "[63 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[64,  6400/50000] loss: 0.0086953, lr: 0.0273475\n",
            "[64, 12800/50000] loss: 0.0110055, lr: 0.0273475\n",
            "[64, 19200/50000] loss: 0.0107734, lr: 0.0273475\n",
            "[64, 25600/50000] loss: 0.0090589, lr: 0.0273475\n",
            "[64, 32000/50000] loss: 0.0104442, lr: 0.0273475\n",
            "[64, 38400/50000] loss: 0.0100100, lr: 0.0273475\n",
            "[64, 44800/50000] loss: 0.0108719, lr: 0.0273475\n",
            "[64 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[65,  6400/50000] loss: 0.0211832, lr: 0.0259592\n",
            "[65, 12800/50000] loss: 0.0124953, lr: 0.0259592\n",
            "[65, 19200/50000] loss: 0.0092790, lr: 0.0259592\n",
            "[65, 25600/50000] loss: 0.0114976, lr: 0.0259592\n",
            "[65, 32000/50000] loss: 0.0109277, lr: 0.0259592\n",
            "[65, 38400/50000] loss: 0.0103046, lr: 0.0259592\n",
            "[65, 44800/50000] loss: 0.0135042, lr: 0.0259592\n",
            "[65 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[66,  6400/50000] loss: 0.0096253, lr: 0.0245947\n",
            "[66, 12800/50000] loss: 0.0097525, lr: 0.0245947\n",
            "[66, 19200/50000] loss: 0.0102257, lr: 0.0245947\n",
            "[66, 25600/50000] loss: 0.0073719, lr: 0.0245947\n",
            "[66, 32000/50000] loss: 0.0094822, lr: 0.0245947\n",
            "[66, 38400/50000] loss: 0.0098916, lr: 0.0245947\n",
            "[66, 44800/50000] loss: 0.0087641, lr: 0.0245947\n",
            "[66 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[67,  6400/50000] loss: 0.0082557, lr: 0.0232554\n",
            "[67, 12800/50000] loss: 0.0090934, lr: 0.0232554\n",
            "[67, 19200/50000] loss: 0.0104299, lr: 0.0232554\n",
            "[67, 25600/50000] loss: 0.0093367, lr: 0.0232554\n",
            "[67, 32000/50000] loss: 0.0078553, lr: 0.0232554\n",
            "[67, 38400/50000] loss: 0.0096434, lr: 0.0232554\n",
            "[67, 44800/50000] loss: 0.0079044, lr: 0.0232554\n",
            "[67 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[68,  6400/50000] loss: 0.0074288, lr: 0.0219425\n",
            "[68, 12800/50000] loss: 0.0083484, lr: 0.0219425\n",
            "[68, 19200/50000] loss: 0.0063069, lr: 0.0219425\n",
            "[68, 25600/50000] loss: 0.0089526, lr: 0.0219425\n",
            "[68, 32000/50000] loss: 0.0084941, lr: 0.0219425\n",
            "[68, 38400/50000] loss: 0.0085436, lr: 0.0219425\n",
            "[68, 44800/50000] loss: 0.0070258, lr: 0.0219425\n",
            "[68 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[69,  6400/50000] loss: 0.0097026, lr: 0.0206573\n",
            "[69, 12800/50000] loss: 0.0082689, lr: 0.0206573\n",
            "[69, 19200/50000] loss: 0.0095103, lr: 0.0206573\n",
            "[69, 25600/50000] loss: 0.0085098, lr: 0.0206573\n",
            "[69, 32000/50000] loss: 0.0083174, lr: 0.0206573\n",
            "[69, 38400/50000] loss: 0.0093467, lr: 0.0206573\n",
            "[69, 44800/50000] loss: 0.0062188, lr: 0.0206573\n",
            "[69 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[70,  6400/50000] loss: 0.0064510, lr: 0.0194011\n",
            "[70, 12800/50000] loss: 0.0094452, lr: 0.0194011\n",
            "[70, 19200/50000] loss: 0.0081013, lr: 0.0194011\n",
            "[70, 25600/50000] loss: 0.0063847, lr: 0.0194011\n",
            "[70, 32000/50000] loss: 0.0077032, lr: 0.0194011\n",
            "[70, 38400/50000] loss: 0.0062095, lr: 0.0194011\n",
            "[70, 44800/50000] loss: 0.0070226, lr: 0.0194011\n",
            "[70 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[71,  6400/50000] loss: 0.0098166, lr: 0.0181751\n",
            "[71, 12800/50000] loss: 0.0068297, lr: 0.0181751\n",
            "[71, 19200/50000] loss: 0.0048465, lr: 0.0181751\n",
            "[71, 25600/50000] loss: 0.0091648, lr: 0.0181751\n",
            "[71, 32000/50000] loss: 0.0077780, lr: 0.0181751\n",
            "[71, 38400/50000] loss: 0.0064799, lr: 0.0181751\n",
            "[71, 44800/50000] loss: 0.0079186, lr: 0.0181751\n",
            "[71 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[72,  6400/50000] loss: 0.0064174, lr: 0.0169806\n",
            "[72, 12800/50000] loss: 0.0080274, lr: 0.0169806\n",
            "[72, 19200/50000] loss: 0.0047018, lr: 0.0169806\n",
            "[72, 25600/50000] loss: 0.0057637, lr: 0.0169806\n",
            "[72, 32000/50000] loss: 0.0047833, lr: 0.0169806\n",
            "[72, 38400/50000] loss: 0.0066518, lr: 0.0169806\n",
            "[72, 44800/50000] loss: 0.0072601, lr: 0.0169806\n",
            "[72 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[73,  6400/50000] loss: 0.0169583, lr: 0.0158187\n",
            "[73, 12800/50000] loss: 0.0105730, lr: 0.0158187\n",
            "[73, 19200/50000] loss: 0.0112334, lr: 0.0158187\n",
            "[73, 25600/50000] loss: 0.0068477, lr: 0.0158187\n",
            "[73, 32000/50000] loss: 0.0086862, lr: 0.0158187\n",
            "[73, 38400/50000] loss: 0.0073938, lr: 0.0158187\n",
            "[73, 44800/50000] loss: 0.0051091, lr: 0.0158187\n",
            "[73 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[74,  6400/50000] loss: 0.0065221, lr: 0.0146906\n",
            "[74, 12800/50000] loss: 0.0066441, lr: 0.0146906\n",
            "[74, 19200/50000] loss: 0.0077362, lr: 0.0146906\n",
            "[74, 25600/50000] loss: 0.0059475, lr: 0.0146906\n",
            "[74, 32000/50000] loss: 0.0069414, lr: 0.0146906\n",
            "[74, 38400/50000] loss: 0.0086005, lr: 0.0146906\n",
            "[74, 44800/50000] loss: 0.0071586, lr: 0.0146906\n",
            "[74 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[75,  6400/50000] loss: 0.0113725, lr: 0.0135973\n",
            "[75, 12800/50000] loss: 0.0079646, lr: 0.0135973\n",
            "[75, 19200/50000] loss: 0.0073664, lr: 0.0135973\n",
            "[75, 25600/50000] loss: 0.0072965, lr: 0.0135973\n",
            "[75, 32000/50000] loss: 0.0070414, lr: 0.0135973\n",
            "[75, 38400/50000] loss: 0.0072899, lr: 0.0135973\n",
            "[75, 44800/50000] loss: 0.0071327, lr: 0.0135973\n",
            "[75 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[76,  6400/50000] loss: 0.0121627, lr: 0.0125401\n",
            "[76, 12800/50000] loss: 0.0051931, lr: 0.0125401\n",
            "[76, 19200/50000] loss: 0.0058279, lr: 0.0125401\n",
            "[76, 25600/50000] loss: 0.0072072, lr: 0.0125401\n",
            "[76, 32000/50000] loss: 0.0073400, lr: 0.0125401\n",
            "[76, 38400/50000] loss: 0.0077968, lr: 0.0125401\n",
            "[76, 44800/50000] loss: 0.0064563, lr: 0.0125401\n",
            "[76 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[77,  6400/50000] loss: 0.0063846, lr: 0.0115198\n",
            "[77, 12800/50000] loss: 0.0044545, lr: 0.0115198\n",
            "[77, 19200/50000] loss: 0.0055968, lr: 0.0115198\n",
            "[77, 25600/50000] loss: 0.0060732, lr: 0.0115198\n",
            "[77, 32000/50000] loss: 0.0077956, lr: 0.0115198\n",
            "[77, 38400/50000] loss: 0.0064422, lr: 0.0115198\n",
            "[77, 44800/50000] loss: 0.0059330, lr: 0.0115198\n",
            "[77 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[78,  6400/50000] loss: 0.0041208, lr: 0.0105375\n",
            "[78, 12800/50000] loss: 0.0053772, lr: 0.0105375\n",
            "[78, 19200/50000] loss: 0.0062374, lr: 0.0105375\n",
            "[78, 25600/50000] loss: 0.0054252, lr: 0.0105375\n",
            "[78, 32000/50000] loss: 0.0046222, lr: 0.0105375\n",
            "[78, 38400/50000] loss: 0.0066829, lr: 0.0105375\n",
            "[78, 44800/50000] loss: 0.0076805, lr: 0.0105375\n",
            "[78 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[79,  6400/50000] loss: 0.0085119, lr: 0.0095942\n",
            "[79, 12800/50000] loss: 0.0101630, lr: 0.0095942\n",
            "[79, 19200/50000] loss: 0.0046357, lr: 0.0095942\n",
            "[79, 25600/50000] loss: 0.0077370, lr: 0.0095942\n",
            "[79, 32000/50000] loss: 0.0046774, lr: 0.0095942\n",
            "[79, 38400/50000] loss: 0.0061422, lr: 0.0095942\n",
            "[79, 44800/50000] loss: 0.0067735, lr: 0.0095942\n",
            "[79 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[80,  6400/50000] loss: 0.0044254, lr: 0.0086908\n",
            "[80, 12800/50000] loss: 0.0048501, lr: 0.0086908\n",
            "[80, 19200/50000] loss: 0.0055562, lr: 0.0086908\n",
            "[80, 25600/50000] loss: 0.0049967, lr: 0.0086908\n",
            "[80, 32000/50000] loss: 0.0048421, lr: 0.0086908\n",
            "[80, 38400/50000] loss: 0.0052647, lr: 0.0086908\n",
            "[80, 44800/50000] loss: 0.0063671, lr: 0.0086908\n",
            "[80 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[81,  6400/50000] loss: 0.0047368, lr: 0.0078282\n",
            "[81, 12800/50000] loss: 0.0045892, lr: 0.0078282\n",
            "[81, 19200/50000] loss: 0.0047086, lr: 0.0078282\n",
            "[81, 25600/50000] loss: 0.0035488, lr: 0.0078282\n",
            "[81, 32000/50000] loss: 0.0044773, lr: 0.0078282\n",
            "[81, 38400/50000] loss: 0.0054638, lr: 0.0078282\n",
            "[81, 44800/50000] loss: 0.0049246, lr: 0.0078282\n",
            "[81 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[82,  6400/50000] loss: 0.0041435, lr: 0.0070073\n",
            "[82, 12800/50000] loss: 0.0062935, lr: 0.0070073\n",
            "[82, 19200/50000] loss: 0.0051173, lr: 0.0070073\n",
            "[82, 25600/50000] loss: 0.0052834, lr: 0.0070073\n",
            "[82, 32000/50000] loss: 0.0050144, lr: 0.0070073\n",
            "[82, 38400/50000] loss: 0.0041339, lr: 0.0070073\n",
            "[82, 44800/50000] loss: 0.0046958, lr: 0.0070073\n",
            "[82 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[83,  6400/50000] loss: 0.0047870, lr: 0.0062287\n",
            "[83, 12800/50000] loss: 0.0065722, lr: 0.0062287\n",
            "[83, 19200/50000] loss: 0.0046585, lr: 0.0062287\n",
            "[83, 25600/50000] loss: 0.0054492, lr: 0.0062287\n",
            "[83, 32000/50000] loss: 0.0055280, lr: 0.0062287\n",
            "[83, 38400/50000] loss: 0.0048276, lr: 0.0062287\n",
            "[83, 44800/50000] loss: 0.0054209, lr: 0.0062287\n",
            "[83 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[84,  6400/50000] loss: 0.0039983, lr: 0.0054934\n",
            "[84, 12800/50000] loss: 0.0051721, lr: 0.0054934\n",
            "[84, 19200/50000] loss: 0.0026319, lr: 0.0054934\n",
            "[84, 25600/50000] loss: 0.0041630, lr: 0.0054934\n",
            "[84, 32000/50000] loss: 0.0044893, lr: 0.0054934\n",
            "[84, 38400/50000] loss: 0.0037512, lr: 0.0054934\n",
            "[84, 44800/50000] loss: 0.0039263, lr: 0.0054934\n",
            "[84 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[85,  6400/50000] loss: 0.0043355, lr: 0.0048020\n",
            "[85, 12800/50000] loss: 0.0034638, lr: 0.0048020\n",
            "[85, 19200/50000] loss: 0.0048685, lr: 0.0048020\n",
            "[85, 25600/50000] loss: 0.0039218, lr: 0.0048020\n",
            "[85, 32000/50000] loss: 0.0057002, lr: 0.0048020\n",
            "[85, 38400/50000] loss: 0.0030294, lr: 0.0048020\n",
            "[85, 44800/50000] loss: 0.0034359, lr: 0.0048020\n",
            "[85 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[86,  6400/50000] loss: 0.0043903, lr: 0.0041552\n",
            "[86, 12800/50000] loss: 0.0056369, lr: 0.0041552\n",
            "[86, 19200/50000] loss: 0.0033173, lr: 0.0041552\n",
            "[86, 25600/50000] loss: 0.0035993, lr: 0.0041552\n",
            "[86, 32000/50000] loss: 0.0042597, lr: 0.0041552\n",
            "[86, 38400/50000] loss: 0.0048442, lr: 0.0041552\n",
            "[86, 44800/50000] loss: 0.0050047, lr: 0.0041552\n",
            "[86 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[87,  6400/50000] loss: 0.0048141, lr: 0.0035537\n",
            "[87, 12800/50000] loss: 0.0047489, lr: 0.0035537\n",
            "[87, 19200/50000] loss: 0.0047206, lr: 0.0035537\n",
            "[87, 25600/50000] loss: 0.0043305, lr: 0.0035537\n",
            "[87, 32000/50000] loss: 0.0031456, lr: 0.0035537\n",
            "[87, 38400/50000] loss: 0.0056672, lr: 0.0035537\n",
            "[87, 44800/50000] loss: 0.0034141, lr: 0.0035537\n",
            "[87 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[88,  6400/50000] loss: 0.0050727, lr: 0.0029979\n",
            "[88, 12800/50000] loss: 0.0046457, lr: 0.0029979\n",
            "[88, 19200/50000] loss: 0.0048885, lr: 0.0029979\n",
            "[88, 25600/50000] loss: 0.0046664, lr: 0.0029979\n",
            "[88, 32000/50000] loss: 0.0039375, lr: 0.0029979\n",
            "[88, 38400/50000] loss: 0.0035817, lr: 0.0029979\n",
            "[88, 44800/50000] loss: 0.0040883, lr: 0.0029979\n",
            "[88 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[89,  6400/50000] loss: 0.0040495, lr: 0.0024885\n",
            "[89, 12800/50000] loss: 0.0057373, lr: 0.0024885\n",
            "[89, 19200/50000] loss: 0.0027720, lr: 0.0024885\n",
            "[89, 25600/50000] loss: 0.0044256, lr: 0.0024885\n",
            "[89, 32000/50000] loss: 0.0040292, lr: 0.0024885\n",
            "[89, 38400/50000] loss: 0.0045824, lr: 0.0024885\n",
            "[89, 44800/50000] loss: 0.0036078, lr: 0.0024885\n",
            "[89 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[90,  6400/50000] loss: 0.0040252, lr: 0.0020260\n",
            "[90, 12800/50000] loss: 0.0038482, lr: 0.0020260\n",
            "[90, 19200/50000] loss: 0.0033404, lr: 0.0020260\n",
            "[90, 25600/50000] loss: 0.0031021, lr: 0.0020260\n",
            "[90, 32000/50000] loss: 0.0050442, lr: 0.0020260\n",
            "[90, 38400/50000] loss: 0.0039675, lr: 0.0020260\n",
            "[90, 44800/50000] loss: 0.0048113, lr: 0.0020260\n",
            "[90 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[91,  6400/50000] loss: 0.0031920, lr: 0.0016106\n",
            "[91, 12800/50000] loss: 0.0037869, lr: 0.0016106\n",
            "[91, 19200/50000] loss: 0.0045077, lr: 0.0016106\n",
            "[91, 25600/50000] loss: 0.0032975, lr: 0.0016106\n",
            "[91, 32000/50000] loss: 0.0039049, lr: 0.0016106\n",
            "[91, 38400/50000] loss: 0.0044973, lr: 0.0016106\n",
            "[91, 44800/50000] loss: 0.0041663, lr: 0.0016106\n",
            "[91 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[92,  6400/50000] loss: 0.0030667, lr: 0.0012429\n",
            "[92, 12800/50000] loss: 0.0031776, lr: 0.0012429\n",
            "[92, 19200/50000] loss: 0.0036778, lr: 0.0012429\n",
            "[92, 25600/50000] loss: 0.0042947, lr: 0.0012429\n",
            "[92, 32000/50000] loss: 0.0039096, lr: 0.0012429\n",
            "[92, 38400/50000] loss: 0.0043520, lr: 0.0012429\n",
            "[92, 44800/50000] loss: 0.0042982, lr: 0.0012429\n",
            "[92 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[93,  6400/50000] loss: 0.0038795, lr: 0.0009231\n",
            "[93, 12800/50000] loss: 0.0039914, lr: 0.0009231\n",
            "[93, 19200/50000] loss: 0.0037383, lr: 0.0009231\n",
            "[93, 25600/50000] loss: 0.0037607, lr: 0.0009231\n",
            "[93, 32000/50000] loss: 0.0044392, lr: 0.0009231\n",
            "[93, 38400/50000] loss: 0.0041316, lr: 0.0009231\n",
            "[93, 44800/50000] loss: 0.0046742, lr: 0.0009231\n",
            "[93 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[94,  6400/50000] loss: 0.0039378, lr: 0.0006514\n",
            "[94, 12800/50000] loss: 0.0032445, lr: 0.0006514\n",
            "[94, 19200/50000] loss: 0.0030252, lr: 0.0006514\n",
            "[94, 25600/50000] loss: 0.0047215, lr: 0.0006514\n",
            "[94, 32000/50000] loss: 0.0032290, lr: 0.0006514\n",
            "[94, 38400/50000] loss: 0.0040480, lr: 0.0006514\n",
            "[94, 44800/50000] loss: 0.0037788, lr: 0.0006514\n",
            "[94 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[95,  6400/50000] loss: 0.0039178, lr: 0.0004279\n",
            "[95, 12800/50000] loss: 0.0027519, lr: 0.0004279\n",
            "[95, 19200/50000] loss: 0.0048307, lr: 0.0004279\n",
            "[95, 25600/50000] loss: 0.0035548, lr: 0.0004279\n",
            "[95, 32000/50000] loss: 0.0031949, lr: 0.0004279\n",
            "[95, 38400/50000] loss: 0.0047836, lr: 0.0004279\n",
            "[95, 44800/50000] loss: 0.0039086, lr: 0.0004279\n",
            "[95 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[96,  6400/50000] loss: 0.0038856, lr: 0.0002525\n",
            "[96, 12800/50000] loss: 0.0049101, lr: 0.0002525\n",
            "[96, 19200/50000] loss: 0.0035704, lr: 0.0002525\n",
            "[96, 25600/50000] loss: 0.0039214, lr: 0.0002525\n",
            "[96, 32000/50000] loss: 0.0059973, lr: 0.0002525\n",
            "[96, 38400/50000] loss: 0.0047790, lr: 0.0002525\n",
            "[96, 44800/50000] loss: 0.0028853, lr: 0.0002525\n",
            "[96 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[97,  6400/50000] loss: 0.0031968, lr: 0.0001249\n",
            "[97, 12800/50000] loss: 0.0041552, lr: 0.0001249\n",
            "[97, 19200/50000] loss: 0.0050687, lr: 0.0001249\n",
            "[97, 25600/50000] loss: 0.0047429, lr: 0.0001249\n",
            "[97, 32000/50000] loss: 0.0035097, lr: 0.0001249\n",
            "[97, 38400/50000] loss: 0.0029359, lr: 0.0001249\n",
            "[97, 44800/50000] loss: 0.0036308, lr: 0.0001249\n",
            "[97 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[98,  6400/50000] loss: 0.0039792, lr: 0.0000439\n",
            "[98, 12800/50000] loss: 0.0046627, lr: 0.0000439\n",
            "[98, 19200/50000] loss: 0.0031029, lr: 0.0000439\n",
            "[98, 25600/50000] loss: 0.0032658, lr: 0.0000439\n",
            "[98, 32000/50000] loss: 0.0034409, lr: 0.0000439\n",
            "[98, 38400/50000] loss: 0.0041108, lr: 0.0000439\n",
            "[98, 44800/50000] loss: 0.0037369, lr: 0.0000439\n",
            "[98 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[99,  6400/50000] loss: 0.0037280, lr: 0.0000062\n",
            "[99, 12800/50000] loss: 0.0038307, lr: 0.0000062\n",
            "[99, 19200/50000] loss: 0.0048515, lr: 0.0000062\n",
            "[99, 25600/50000] loss: 0.0033435, lr: 0.0000062\n",
            "[99, 32000/50000] loss: 0.0028253, lr: 0.0000062\n",
            "[99, 38400/50000] loss: 0.0035551, lr: 0.0000062\n",
            "[99, 44800/50000] loss: 0.0034208, lr: 0.0000062\n",
            "[99 epoch] Accuracy of the network on the validation images: 91 %\n",
            "[100,  6400/50000] loss: 0.0041411, lr: 0.0000000\n",
            "[100, 12800/50000] loss: 0.0025908, lr: 0.0000000\n",
            "[100, 19200/50000] loss: 0.0029600, lr: 0.0000000\n",
            "[100, 25600/50000] loss: 0.0050555, lr: 0.0000000\n",
            "[100, 32000/50000] loss: 0.0046565, lr: 0.0000000\n",
            "[100, 38400/50000] loss: 0.0028392, lr: 0.0000000\n",
            "[100, 44800/50000] loss: 0.0043830, lr: 0.0000000\n",
            "[100 epoch] Accuracy of the network on the validation images: 91 %\n",
            "Finished Training\n",
            "time : 24813.852006435394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWiV6ke5CfS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "                \n",
        "        for i in range(labels.shape[0]):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))            \n",
        "            \n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}